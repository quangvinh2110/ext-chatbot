{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d241c26c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from functools import lru_cache\n",
        "import json\n",
        "import json5\n",
        "from datetime import datetime\n",
        "from typing import List\n",
        "\n",
        "from langchain_core.messages.tool import ToolCall\n",
        "from langchain_core.messages import (\n",
        "    AnyMessage,\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage,\n",
        ")\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.embeddings import InfinityEmbeddings\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e306567",
      "metadata": {},
      "source": [
        "# Setup components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "89608e27",
      "metadata": {},
      "outputs": [],
      "source": [
        "LLM_BASE_URL=os.getenv(\"LLM_BASE_URL\")\n",
        "LLM_MODEL=os.getenv(\"LLM_MODEL\")\n",
        "LLM_API_KEY=os.getenv(\"LLM_API_KEY\")\n",
        "\n",
        "EMBED_BASE_URL=os.getenv(\"EMBED_BASE_URL\")\n",
        "EMBED_MODEL=os.getenv(\"EMBED_MODEL\")\n",
        "\n",
        "\n",
        "@lru_cache()\n",
        "def get_llm_model():\n",
        "    return ChatOpenAI(\n",
        "        model=LLM_MODEL,\n",
        "        base_url=LLM_BASE_URL,\n",
        "        api_key=LLM_API_KEY,\n",
        "        temperature=0.7,\n",
        "        top_p=0.8,\n",
        "        presence_penalty=1,\n",
        "        extra_body = {\n",
        "            'chat_template_kwargs': {'enable_thinking': False},\n",
        "            \"top_k\": 20,\n",
        "            \"mip_p\": 0,\n",
        "        },\n",
        "    )\n",
        "\n",
        "@lru_cache()\n",
        "def get_thinking_llm_model():\n",
        "    return ChatOpenAI(\n",
        "        model=LLM_MODEL,\n",
        "        base_url=LLM_BASE_URL,\n",
        "        api_key=LLM_API_KEY,\n",
        "        temperature=0.6,\n",
        "        top_p=0.95,\n",
        "        presence_penalty=1,\n",
        "        extra_body = {\n",
        "            'chat_template_kwargs': {'enable_thinking': True},\n",
        "            \"top_k\": 20,\n",
        "            \"mip_p\": 0,\n",
        "        },\n",
        "    )\n",
        "\n",
        "@lru_cache()\n",
        "def get_embedding_model():\n",
        "    return InfinityEmbeddings(\n",
        "        model=EMBED_MODEL,\n",
        "        infinity_api_url=EMBED_BASE_URL,\n",
        "    )\n",
        "\n",
        "\n",
        "@lru_cache()\n",
        "def get_vector_store():\n",
        "    client = QdrantClient(\n",
        "        url=\"http://localhost\",\n",
        "        grpc_port=6334,\n",
        "        prefer_grpc=True,\n",
        "    )\n",
        "    embedding_model = get_embedding_model()\n",
        "    client.create_collection(\n",
        "        collection_name=\"demo\",\n",
        "        vectors_config=VectorParams(\n",
        "            size=len(embedding_model.embed_query(\"Hello\")), \n",
        "            distance=Distance.COSINE\n",
        "        ),\n",
        "    )\n",
        "    return QdrantVectorStore(\n",
        "        client=client,\n",
        "        collection_name=\"demo\",\n",
        "        embedding=embedding_model,\n",
        "    )\n",
        "\n",
        "\n",
        "# @lru_cache()\n",
        "# def get_sqlite_db():\n",
        "#     return SQLDatabase.from_uri(\"sqlite:////Users/vinhnguyen/Projects/ext-chatbot/resources/database/batdongsan.db\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ecab7f",
      "metadata": {},
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456d88dd",
      "metadata": {},
      "source": [
        "## Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b2979e68",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from src.tools.table import create_sqlite, create_faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6fd73e84",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BĐS Cho thuê 500', 'BĐS Bán 500']\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "tables = []\n",
        "for filepath in glob.glob(\"/Users/vinhnguyen/Projects/ext-chatbot/resources/processed_data/batdongsan_1/*.json\"):\n",
        "    table_name = \".\".join(filepath.split(\"/\")[-1].split(\".\")[:-1])\n",
        "    with open(filepath, \"r\") as f:\n",
        "        table = json.load(f)\n",
        "        table[\"pydantic_schema\"][\"title\"] = table_name\n",
        "        if len(table[\"transformed_data\"]) > 100:\n",
        "            tables.append(table)\n",
        "\n",
        "print([table[\"pydantic_schema\"][\"title\"] for table in tables])\n",
        "print(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2a5586",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding BĐS Cho thuê 500.ID: 100%|██████████| 500/500 [00:02<00:00, 170.60values/s]\n",
            "Embedding BĐS Cho thuê 500.Dự án: 100%|██████████| 34/34 [00:00<00:00, 91.63values/s]\n",
            "Embedding BĐS Cho thuê 500.Giá/m²/tháng: 100%|██████████| 492/492 [00:02<00:00, 167.45values/s]\n",
            "Embedding BĐS Cho thuê 500.Ngày có thể chuyển vào: 100%|██████████| 61/61 [00:00<00:00, 119.56values/s]\n",
            "Embedding BĐS Cho thuê 500.Hướng: 100%|██████████| 8/8 [00:00<00:00, 66.63values/s]\n",
            "Embedding BĐS Cho thuê 500.Nội thất: 100%|██████████| 5/5 [00:00<00:00, 44.89values/s]\n",
            "Embedding BĐS Cho thuê 500.Phường/Xã: 100%|██████████| 15/15 [00:00<00:00, 82.35values/s]\n",
            "Embedding BĐS Cho thuê 500.Tình trạng: 100%|██████████| 4/4 [00:00<00:00, 39.47values/s]\n",
            "Embedding BĐS Cho thuê 500.Cho phép nuôi thú cưng: 100%|██████████| 3/3 [00:00<00:00, 33.10values/s]\n",
            "Embedding BĐS Cho thuê 500.Bếp: 100%|██████████| 4/4 [00:00<00:00, 41.04values/s]\n",
            "Embedding BĐS Cho thuê 500.Điều hòa: 100%|██████████| 5/5 [00:00<00:00, 46.14values/s]\n",
            "Embedding BĐS Cho thuê 500.Nóng lạnh: 100%|██████████| 3/3 [00:00<00:00, 37.06values/s]\n",
            "Embedding BĐS Cho thuê 500.Bãi đỗ xe: 100%|██████████| 5/5 [00:00<00:00, 48.14values/s]\n",
            "Embedding BĐS Cho thuê 500.Thời hạn thuê tối thiểu: 100%|██████████| 5/5 [00:00<00:00, 45.76values/s]\n",
            "Embedding BĐS Cho thuê 500.Phí dịch vụ: 100%|██████████| 21/21 [00:00<00:00, 103.22values/s]\n",
            "Embedding BĐS Cho thuê 500.Tiền điện nước: 100%|██████████| 5/5 [00:00<00:00, 33.11values/s]\n",
            "Embedding BĐS Cho thuê 500.Internet: 100%|██████████| 4/4 [00:00<00:00, 46.14values/s]\n",
            "Embedding BĐS Cho thuê 500.Người liên hệ: 100%|██████████| 16/16 [00:00<00:00, 97.03values/s]\n",
            "Embedding BĐS Cho thuê 500.SĐT liên hệ: 100%|██████████| 500/500 [00:02<00:00, 178.50values/s]\n",
            "Embedding BĐS Cho thuê 500.Zalo: 100%|██████████| 2/2 [00:00<00:00, 12.05values/s]\n",
            "Embedding BĐS Cho thuê 500.Email: 100%|██████████| 500/500 [00:02<00:00, 171.09values/s]\n",
            "Embedding BĐS Cho thuê 500.Ghi chú: 100%|██████████| 6/6 [00:00<00:00, 28.70values/s]\n",
            "Embedding BĐS Cho thuê 500.Loại BĐS: 100%|██████████| 13/13 [00:00<00:00, 69.63values/s]\n",
            "Embedding BĐS Cho thuê 500.Quận/Huyện: 100%|██████████| 38/38 [00:00<00:00, 151.92values/s]\n",
            "Embedding BĐS Cho thuê 500.Tiêu đề: 100%|██████████| 497/497 [00:02<00:00, 176.60values/s]\n",
            "Embedding BĐS Cho thuê 500.Tỉnh/TP: 100%|██████████| 8/8 [00:00<00:00, 40.21values/s]\n",
            "Embedding BĐS Cho thuê 500.Địa chỉ: 100%|██████████| 500/500 [00:02<00:00, 170.93values/s]\n",
            "Embedding BĐS Cho thuê 500.Địa chỉ_đường: 100%|██████████| 141/141 [00:01<00:00, 140.82values/s]\n",
            "Embedding BĐS Cho thuê 500.An ninh: 100%|██████████| 5/5 [00:00<00:00, 39.24values/s]\n",
            "Embedding BĐS Cho thuê 500.Thang máy: 100%|██████████| 3/3 [00:00<00:00, 32.59values/s]\n",
            "Embedding BĐS Cho thuê 500.Ban công/Sân thượng: 100%|██████████| 4/4 [00:00<00:00, 41.09values/s]\n",
            "Embedding BĐS Cho thuê 500.Tiện ích lân cận: 100%|██████████| 481/481 [00:02<00:00, 169.54values/s]\n",
            "Embedding BĐS Cho thuê 500.Khoảng cách tới trung tâm: 100%|██████████| 144/144 [00:00<00:00, 153.40values/s]\n",
            "Embedding BĐS Cho thuê 500.Tiền cọc: 100%|██████████| 474/474 [00:03<00:00, 151.31values/s]\n",
            "Embedding BĐS Cho thuê 500.Khoảng cách tới trung tâm_đơn vị: 100%|██████████| 1/1 [00:00<00:00, 13.00values/s]\n",
            "Embedding BĐS Cho thuê 500.Tiền cọc_Số tháng: 100%|██████████| 3/3 [00:00<00:00, 35.20values/s]\n",
            "Embedding BĐS Bán 500.ID: 100%|██████████| 500/500 [00:02<00:00, 168.87values/s]\n",
            "Embedding BĐS Bán 500.Dự án: 100%|██████████| 37/37 [00:00<00:00, 126.49values/s]\n",
            "Embedding BĐS Bán 500.Giá/m²: 100%|██████████| 451/451 [00:03<00:00, 146.64values/s]\n",
            "Embedding BĐS Bán 500.Giá/m²_don_vi: 100%|██████████| 1/1 [00:00<00:00,  9.67values/s]\n",
            "Embedding BĐS Bán 500.Ngày hết hạn: 100%|██████████| 202/202 [00:01<00:00, 137.40values/s]\n",
            "Embedding BĐS Bán 500.Hướng nhà: 100%|██████████| 8/8 [00:00<00:00, 65.68values/s]\n",
            "Embedding BĐS Bán 500.Hướng ban công: 100%|██████████| 9/9 [00:00<00:00, 71.57values/s]\n",
            "Embedding BĐS Bán 500.Nội thất: 100%|██████████| 5/5 [00:00<00:00, 46.03values/s]\n",
            "Embedding BĐS Bán 500.Pháp lý: 100%|██████████| 6/6 [00:00<00:00, 42.82values/s]\n",
            "Embedding BĐS Bán 500.Tình trạng: 100%|██████████| 6/6 [00:00<00:00, 42.48values/s]\n",
            "Embedding BĐS Bán 500.Năm xây dựng: 100%|██████████| 17/17 [00:00<00:00, 106.10values/s]\n",
            "Embedding BĐS Bán 500.Chủ đầu tư: 100%|██████████| 16/16 [00:00<00:00, 86.52values/s]\n",
            "Embedding BĐS Bán 500.Bãi đỗ xe: 100%|██████████| 5/5 [00:00<00:00, 45.02values/s]\n",
            "Embedding BĐS Bán 500.Email: 100%|██████████| 500/500 [00:02<00:00, 169.43values/s]\n",
            "Embedding BĐS Bán 500.Hoa hồng: 100%|██████████| 6/6 [00:00<00:00, 32.73values/s]\n",
            "Embedding BĐS Bán 500.Ghi chú: 100%|██████████| 6/6 [00:00<00:00, 51.58values/s]\n",
            "Embedding BĐS Bán 500.Loại BĐS: 100%|██████████| 14/14 [00:00<00:00, 84.42values/s]\n",
            "Embedding BĐS Bán 500.Phường/Xã: 100%|██████████| 15/15 [00:00<00:00, 111.96values/s]\n",
            "Embedding BĐS Bán 500.Quận/Huyện: 100%|██████████| 36/36 [00:00<00:00, 122.34values/s]\n",
            "Embedding BĐS Bán 500.Tiêu đề: 100%|██████████| 498/498 [00:03<00:00, 153.58values/s]\n",
            "Embedding BĐS Bán 500.Tỉnh/TP: 100%|██████████| 8/8 [00:00<00:00, 45.83values/s]\n",
            "Embedding BĐS Bán 500.Địa chỉ: 100%|██████████| 500/500 [00:02<00:00, 182.51values/s]\n",
            "Embedding BĐS Bán 500.Địa chỉ_Tên đường: 100%|██████████| 137/137 [00:01<00:00, 128.90values/s]\n",
            "Embedding BĐS Bán 500.View: 100%|██████████| 6/6 [00:00<00:00, 45.19values/s]\n",
            "Embedding BĐS Bán 500.Tiện ích: 100%|██████████| 500/500 [00:03<00:00, 152.79values/s]\n",
            "Embedding BĐS Bán 500.Ngày đăng: 100%|██████████| 170/170 [00:01<00:00, 149.35values/s]\n",
            "Embedding BĐS Bán 500.Người liên hệ: 100%|██████████| 16/16 [00:00<00:00, 79.29values/s]\n",
            "Embedding BĐS Bán 500.SĐT liên hệ: 100%|██████████| 500/500 [00:02<00:00, 174.18values/s]\n"
          ]
        }
      ],
      "source": [
        "# for table in tables:\n",
        "#     create_sqlite(\n",
        "#         schema=table[\"pydantic_schema\"],\n",
        "#         column_groups=table[\"column_groups\"],\n",
        "#         data=table[\"transformed_data\"],\n",
        "#         db_path=\"/Users/vinhnguyen/Projects/ext-chatbot/resources/database/batdongsan.db\",\n",
        "#     )\n",
        "\n",
        "\n",
        "for table in tables:\n",
        "    create_faiss(\n",
        "        schema=table[\"pydantic_schema\"],\n",
        "        db_path=\"/Users/vinhnguyen/Projects/ext-chatbot/resources/database/batdongsan.db\",\n",
        "        faiss_dir=\"/Users/vinhnguyen/Projects/ext-chatbot/resources/faiss/\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "abb6f635",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Request more files from PO to test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f81d17",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bf394eb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_fn(text: str) -> tuple[str, str]:\n",
        "    \"\"\"Extract function name and arguments from tool call text.\"\"\"\n",
        "    fn_name, fn_args = '', ''\n",
        "    fn_name_s = '\"name\": \"'\n",
        "    fn_name_e = '\", \"'\n",
        "    fn_args_s = '\"arguments\": '\n",
        "    \n",
        "    i = text.find(fn_name_s)\n",
        "    k = text.find(fn_args_s)\n",
        "    \n",
        "    if i > 0:\n",
        "        _text = text[i + len(fn_name_s):]\n",
        "        j = _text.find(fn_name_e)\n",
        "        if j > -1:\n",
        "            fn_name = _text[:j]\n",
        "    \n",
        "    if k > 0:\n",
        "        fn_args = text[k + len(fn_args_s):]\n",
        "    \n",
        "    fn_args = fn_args.strip()\n",
        "    if len(fn_args) > 2:\n",
        "        fn_args = fn_args[:-1]\n",
        "    else:\n",
        "        fn_args = ''\n",
        "    \n",
        "    return fn_name, fn_args\n",
        "\n",
        "\n",
        "def postprocess_ai_message(\n",
        "    ai_message: AIMessage,\n",
        ") -> List[AIMessage]:\n",
        "    \"\"\"\n",
        "    Convert AIMessage with <tool_call> tags to proper LangChain message with tool calls and leave it in a list to integrate with MessagesState.\n",
        "    Assumes all content is text (no multimodal).\n",
        "    \"\"\"\n",
        "    tool_id = 1\n",
        "    \n",
        "    content: str = ai_message.content if isinstance(ai_message.content, str) else str(ai_message.content)\n",
        "    \n",
        "    # Handle <think> tags - skip tool call parsing inside thinking\n",
        "    if '<think>' in content:\n",
        "        if '</think>' not in content:\n",
        "            # Incomplete thinking, add as regular message\n",
        "            return [ai_message]\n",
        "        \n",
        "        # Split thinking from rest of content\n",
        "        parts = content.split('</think>')\n",
        "        content = parts[-1]\n",
        "        \n",
        "    \n",
        "    # Find tool calls in content\n",
        "    if '<tool_call>' not in content:\n",
        "        # No tool calls, add as regular message\n",
        "        return [AIMessage(content=content.strip())]\n",
        "    \n",
        "    # Split content by tool calls\n",
        "    tool_call_list = content.split('<tool_call>')\n",
        "    pre_text = tool_call_list[0].strip()\n",
        "    tool_calls: List[ToolCall] = []\n",
        "    \n",
        "    # Process each tool call\n",
        "    for txt in tool_call_list[1:]:\n",
        "        if not txt.strip():\n",
        "            continue\n",
        "        \n",
        "        # Handle incomplete tool calls (no closing tag)\n",
        "        if '</tool_call>' not in txt:\n",
        "            fn_name, fn_args = extract_fn(txt)\n",
        "            if fn_name:\n",
        "                tool_calls.append(\n",
        "                    ToolCall(\n",
        "                        name=fn_name,\n",
        "                        args=json.loads(fn_args) if fn_args else {},\n",
        "                        id=str(tool_id),\n",
        "                    )\n",
        "                )\n",
        "                tool_id += 1\n",
        "                # new_messages.append(AIMessage(content='', tool_calls=tool_calls))\n",
        "            continue\n",
        "        \n",
        "        # Handle complete tool calls\n",
        "        one_tool_call_txt = txt.split('</tool_call>')[0].strip()\n",
        "        \n",
        "        try:\n",
        "            # Try to parse as JSON\n",
        "            fn = json5.loads(one_tool_call_txt)\n",
        "            if 'name' in fn and 'arguments' in fn:\n",
        "                tool_calls.append(\n",
        "                    ToolCall(\n",
        "                        name=fn['name'],\n",
        "                        args=fn['arguments'],\n",
        "                        id=str(tool_id),\n",
        "                    )\n",
        "                )\n",
        "                tool_id += 1\n",
        "                # new_messages.append(AIMessage(content='', tool_calls=tool_calls))\n",
        "        except Exception:\n",
        "            # Fallback to manual extraction\n",
        "            fn_name, fn_args = extract_fn(one_tool_call_txt)\n",
        "            if fn_name:\n",
        "                tool_calls.append(\n",
        "                    ToolCall(\n",
        "                        name=fn_name,\n",
        "                        args=json.loads(fn_args) if fn_args else {},\n",
        "                        id=str(tool_id),\n",
        "                    )\n",
        "                )\n",
        "                tool_id += 1\n",
        "                # new_messages.append(AIMessage(content='', tool_calls=tool_calls))\n",
        "        \n",
        "    if tool_calls:\n",
        "        return [AIMessage(content=pre_text, tool_calls=tool_calls)]\n",
        "    elif pre_text:\n",
        "        return [AIMessage(content=pre_text)]\n",
        "    else:\n",
        "        return [AIMessage(content=content)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "id": "5668ae44",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import BaseModel\n",
        "\n",
        "\n",
        "def get_today_date_en() -> str:\n",
        "    \"\"\"Get today's date formatted for system message.\"\"\"\n",
        "    today = datetime.today()\n",
        "    day_names = [\n",
        "        \"Monday\",\n",
        "        \"Tuesday\",\n",
        "        \"Wednesday\",\n",
        "        \"Thursday\",\n",
        "        \"Friday\",\n",
        "        \"Saturday\",\n",
        "        \"Sunday\",\n",
        "    ]\n",
        "    day_of_week = day_names[today.weekday()]\n",
        "    month_name_full = today.strftime(\"%B\")\n",
        "    if today.day % 10 == 1 and today.day != 11:\n",
        "        day_suffix = \"st\"\n",
        "    elif today.day % 10 == 2 and today.day != 12:\n",
        "        day_suffix = \"nd\"\n",
        "    elif today.day % 10 == 3 and today.day != 13:\n",
        "        day_suffix = \"rd\"\n",
        "    else:\n",
        "        day_suffix = \"th\"\n",
        "    return f\"{day_of_week}, {month_name_full} {today.day}{day_suffix}, {today.year}\"\n",
        "\n",
        "\n",
        "def get_today_date_vi() -> str:\n",
        "    today = datetime.today()\n",
        "    day_names = [\n",
        "        \"Thứ hai\",\n",
        "        \"Thứ ba\",\n",
        "        \"Thứ tư\",\n",
        "        \"Thứ năm\",\n",
        "        \"Thứ sáu\",\n",
        "        \"Thứ bảy\",\n",
        "        \"Chủ nhật\",\n",
        "    ]\n",
        "    day_of_week = day_names[today.weekday()]\n",
        "    return f\"{day_of_week}, ngày {today.day}, tháng {today.month}, năm {today.year}\"\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "def preprocess_messages(\n",
        "    state: BaseModel,\n",
        "    system_prompt: str,\n",
        ") -> List[AnyMessage]:\n",
        "    \"\"\"\n",
        "    Convert LangChain messages with tool calls to plaintext format with <tool_call> tags.\n",
        "    Converts ToolMessages to <tool_response> tags.\n",
        "    Assumes all content is text (no multimodal).\n",
        "    \"\"\"\n",
        "    if \"messages\" not in state:\n",
        "        raise ValueError(\"messages not found in state\")\n",
        "    messages: List[AnyMessage] = state[\"messages\"]\n",
        "    new_messages = []\n",
        "\n",
        "    if messages[0].type == \"system\":\n",
        "        new_messages.append(messages[0])\n",
        "    else:\n",
        "        date_info = \"Hôm nay là {date}.\\n\".format(date=get_today_date_vi())\n",
        "        new_messages.append(SystemMessage(\n",
        "            content=date_info + system_prompt\n",
        "        ))\n",
        "\n",
        "    for msg in messages[1:]:\n",
        "        # Pass through human messages as-is\n",
        "        if msg.type == \"human\":\n",
        "            new_messages.append(msg)\n",
        "            continue\n",
        "        # Handle AI messages with tool calls\n",
        "        elif msg.type == \"ai\":\n",
        "            content = msg.content if isinstance(msg.content, str) else str(msg.content)\n",
        "            \n",
        "            # Convert tool calls to plaintext format\n",
        "            if msg.tool_calls:\n",
        "                for tool_call in msg.tool_calls:\n",
        "                    fc = {\n",
        "                        'name': tool_call['name'],\n",
        "                        'arguments': tool_call['args']\n",
        "                    }\n",
        "                    fc_str = json.dumps(fc, ensure_ascii=False)\n",
        "                    tool_call_text = f'<tool_call>\\n{fc_str}\\n</tool_call>'\n",
        "                    \n",
        "                    # Append to content\n",
        "                    if content:\n",
        "                        content += '\\n' + tool_call_text\n",
        "                    else:\n",
        "                        content = tool_call_text\n",
        "            \n",
        "            # Merge consecutive AI messages\n",
        "            if new_messages and new_messages[-1].type == \"ai\":\n",
        "                prev_content = new_messages[-1].content\n",
        "                if prev_content and not prev_content.endswith('\\n'):\n",
        "                    prev_content += '\\n'\n",
        "                new_messages[-1] = AIMessage(content=prev_content + content)\n",
        "            else:\n",
        "                new_messages.append(AIMessage(content=content))\n",
        "            continue\n",
        "        # Handle tool messages - convert to <tool_response> wrapped in HumanMessage\n",
        "        elif msg.type == \"tool\":\n",
        "            content = msg.content if isinstance(msg.content, str) else str(msg.content)\n",
        "            response_text = f'<tool_response>\\n{content}\\n</tool_response>'\n",
        "            if new_messages and new_messages[-1].type == \"human\":\n",
        "                prev_content = new_messages[-1].content\n",
        "                prev_content += '\\n' + response_text\n",
        "                new_messages[-1] = HumanMessage(content=prev_content)\n",
        "            else:\n",
        "                new_messages.append(HumanMessage(content=response_text))\n",
        "            continue\n",
        "\n",
        "    return new_messages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0fd1de5",
      "metadata": {},
      "source": [
        "# SQLite Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "id": "5e4d5e6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any, Dict, Iterable, List, Literal, Sequence, Tuple, Union, Optional\n",
        "from sqlalchemy import (\n",
        "    MetaData,\n",
        "    Table,\n",
        "    create_engine,\n",
        "    inspect,\n",
        "    text,\n",
        "    Column,\n",
        ")\n",
        "from sqlalchemy.engine import Engine, Result\n",
        "from sqlalchemy.exc import ProgrammingError, SQLAlchemyError\n",
        "from sqlalchemy.types import NullType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "id": "bbac486b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def truncate_word(content: Any, *, length: int, suffix: str = \"...\") -> str:\n",
        "    \"\"\"Truncate a string to a certain number of words, based on the max string length.\"\"\"\n",
        "    if not isinstance(content, str) or length <= 0:\n",
        "        return content\n",
        "    if len(content) <= length:\n",
        "        return content\n",
        "    return content[: length - len(suffix)].rsplit(\" \", 1)[0] + suffix\n",
        "\n",
        "\n",
        "class SQLiteDatabase:\n",
        "    \"\"\"SQLAlchemy wrapper around a SQLite database with column comments support.\"\"\"\n",
        "\n",
        "    def _render_type(self, col_type: Any, *, default: str = \"TEXT\") -> str:\n",
        "        \"\"\"Render SQLAlchemy type using this engine's dialect when possible.\"\"\"\n",
        "        if col_type is None or isinstance(col_type, NullType):\n",
        "            return default\n",
        "        try:\n",
        "            compiled = col_type.compile(dialect=self._engine.dialect)\n",
        "            if isinstance(compiled, str) and compiled.strip():\n",
        "                return compiled.strip()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            rendered = str(col_type)\n",
        "            return rendered.strip() if rendered.strip() else default\n",
        "        except Exception:\n",
        "            return default\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        engine: Engine,\n",
        "        ignore_tables: Optional[List[str]] = None,\n",
        "        include_tables: Optional[List[str]] = None,\n",
        "        indexes_in_table_info: bool = False,\n",
        "        max_string_length: int = 200,\n",
        "        lazy_table_reflection: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create SQLite database wrapper.\n",
        "        \n",
        "        Args:\n",
        "            engine: SQLAlchemy engine connected to SQLite database\n",
        "            ignore_tables: List of table names to ignore\n",
        "            include_tables: List of table names to include (mutually exclusive with ignore_tables)\n",
        "            indexes_in_table_info: Whether to include index information in table info\n",
        "            max_string_length: Maximum string length for truncating values\n",
        "            lazy_table_reflection: Whether to lazily reflect tables\n",
        "        \"\"\"\n",
        "        self._engine = engine\n",
        "        if self._engine.dialect.name != \"sqlite\":\n",
        "            raise ValueError(\"SQLiteDatabase only supports SQLite databases\")\n",
        "        \n",
        "        if include_tables and ignore_tables:\n",
        "            raise ValueError(\"Cannot specify both include_tables and ignore_tables\")\n",
        "\n",
        "        self._inspector = inspect(self._engine)\n",
        "        self._all_tables = set(self._inspector.get_table_names())\n",
        "\n",
        "        self._include_tables = set(include_tables) if include_tables else set()\n",
        "        if self._include_tables:\n",
        "            missing_tables = self._include_tables - self._all_tables\n",
        "            if missing_tables:\n",
        "                raise ValueError(f\"include_tables {missing_tables} not found in database\")\n",
        "        \n",
        "        self._ignore_tables = set(ignore_tables) if ignore_tables else set()\n",
        "        if self._ignore_tables:\n",
        "            missing_tables = self._ignore_tables - self._all_tables\n",
        "            if missing_tables:\n",
        "                raise ValueError(f\"ignore_tables {missing_tables} not found in database\")\n",
        "        \n",
        "        usable_tables = self.get_usable_table_names()\n",
        "        self._usable_tables = set(usable_tables) if usable_tables else self._all_tables\n",
        "\n",
        "        self._indexes_in_table_info = indexes_in_table_info\n",
        "        self._max_string_length = max_string_length\n",
        "\n",
        "        self._metadata = MetaData()\n",
        "        if not lazy_table_reflection:\n",
        "            self._metadata.reflect(\n",
        "                bind=self._engine,\n",
        "                only=list(self._usable_tables),\n",
        "            )\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_uri(\n",
        "        cls,\n",
        "        database_uri: str,\n",
        "        engine_args: Optional[dict] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> \"SQLiteDatabase\":\n",
        "        \"\"\"Construct a SQLiteDatabase from URI.\"\"\"\n",
        "        _engine_args = engine_args or {}\n",
        "        return cls(create_engine(database_uri, **_engine_args), **kwargs)\n",
        "\n",
        "\n",
        "    @property\n",
        "    def dialect(self) -> str:\n",
        "        \"\"\"Return string representation of dialect to use.\"\"\"\n",
        "        return \"SQLite\"\n",
        "\n",
        "\n",
        "    def get_usable_table_names(self) -> Iterable[str]:\n",
        "        \"\"\"Get names of tables available.\"\"\"\n",
        "        if self._include_tables:\n",
        "            base = set(self._include_tables)\n",
        "        else:\n",
        "            base = self._all_tables - self._ignore_tables\n",
        "\n",
        "        # filter out metadata tables (companion EAV tables)\n",
        "        base = {tbl for tbl in base if not tbl.endswith(\"__metadata\")}\n",
        "        return sorted(base)\n",
        "\n",
        "\n",
        "    def get_column_datatype(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        column_name: str,\n",
        "        default: str = \"TEXT\",\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Return SQL datatype for a column in a table.\n",
        "\n",
        "        Notes:\n",
        "        - Uses SQLAlchemy inspector, so it does not require table reflection.\n",
        "        - Returns `default` when the table/column is not found or the type is unknown.\n",
        "        \"\"\"\n",
        "        all_table_names = set(self.get_usable_table_names())\n",
        "        if table_name not in all_table_names:\n",
        "            raise ValueError(\n",
        "                f\"Table '{table_name}' not found in database. Available tables: {sorted(all_table_names)}\"\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            cols = self._inspector.get_columns(table_name)\n",
        "        except SQLAlchemyError:\n",
        "            return default\n",
        "\n",
        "        for col in cols:\n",
        "            if col.get(\"name\") != column_name:\n",
        "                continue\n",
        "            col_type = col.get(\"type\")\n",
        "            return self._render_type(col_type, default=default)\n",
        "\n",
        "        return default\n",
        "\n",
        "\n",
        "    def get_table_info(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        get_col_comments: bool = False,\n",
        "        allowed_col_names: Optional[List[str]] = None,\n",
        "        sample_count: Optional[int] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Get information about a specified table.\n",
        "\n",
        "        Args:\n",
        "            table_name: Name of the table to get info for\n",
        "            get_col_comments: Whether to include column comments in the output\n",
        "            allowed_col_names: If provided, only include these columns in the output.\n",
        "                              If None, include all columns.\n",
        "            sample_count: Number of distinct example values to include for each column.\n",
        "                          If None, no example values are included.\n",
        "\n",
        "        Returns:\n",
        "            String containing table schema (CREATE TABLE statement) and optionally\n",
        "            column comments and sample rows.\n",
        "        \"\"\"\n",
        "        all_table_names = list(self.get_usable_table_names())\n",
        "        if table_name not in all_table_names:\n",
        "            raise ValueError(f\"Table '{table_name}' not found in database. Available tables: {all_table_names}\")\n",
        "\n",
        "        # Ensure table is reflected\n",
        "        metadata_table_names = [tbl.name for tbl in self._metadata.sorted_tables]\n",
        "        if table_name not in metadata_table_names:\n",
        "            self._metadata.reflect(\n",
        "                bind=self._engine,\n",
        "                only=[table_name],\n",
        "            )\n",
        "\n",
        "        # Find the table object\n",
        "        table = None\n",
        "        for tbl in self._metadata.sorted_tables:\n",
        "            if tbl.name == table_name:\n",
        "                table = tbl\n",
        "                break\n",
        "\n",
        "        if table is None:\n",
        "            raise ValueError(f\"Table '{table_name}' could not be reflected\")\n",
        "\n",
        "        # Remove NullType columns\n",
        "        try:\n",
        "            for _, v in table.columns.items():\n",
        "                if type(v.type) is NullType:\n",
        "                    table._columns.remove(v)\n",
        "        except AttributeError:\n",
        "            for _, v in dict(table.columns).items():\n",
        "                if type(v.type) is NullType:\n",
        "                    table._columns.remove(v)\n",
        "\n",
        "        # Filter columns if allowed_col_names is specified\n",
        "        display_columns = list(table.columns) if not allowed_col_names else [col for col in table.columns if col.name in allowed_col_names]\n",
        "        if not display_columns:\n",
        "            raise ValueError(f\"No matching columns found. Requested: {allowed_col_names}\")\n",
        "\n",
        "        # Get sample values for columns if requested\n",
        "        column_sample_values: Dict[str, List[str]] = {}\n",
        "        if sample_count:\n",
        "            column_sample_values = self._get_sample_values(\n",
        "                table, display_columns, sample_count\n",
        "            )\n",
        "\n",
        "        # Build custom CREATE TABLE statement with filtered columns\n",
        "        col_defs = []\n",
        "        column_descriptions = (\n",
        "            self._get_column_descriptions_from_metadata(table_name)\n",
        "            if get_col_comments\n",
        "            else {}\n",
        "        )\n",
        "        for col in display_columns:\n",
        "            col_type = self._render_type(col.type, default=\"TEXT\")\n",
        "            col_def = f'\\t\"{col.name}\" {col_type}'\n",
        "            \n",
        "            # Build comment with description and example values\n",
        "            comment_parts = []\n",
        "            col_cmt = column_descriptions.get(col.name, \"\")\n",
        "            if col_cmt:\n",
        "                comment_parts.append(col_cmt)\n",
        "            \n",
        "            # Add sample values if available\n",
        "            if col.name in column_sample_values and column_sample_values[col.name]:\n",
        "                sample_values = column_sample_values[col.name]\n",
        "                examples_str = \", \".join(str(v) for v in sample_values)\n",
        "                comment_parts.append(f\"Ví dụ: {examples_str},...\")\n",
        "            \n",
        "            if comment_parts:\n",
        "                comment_text = \" \".join(comment_parts)\n",
        "                col_def = f\"{col_def}\\t/* {comment_text} */\"\n",
        "            \n",
        "            col_defs.append(col_def)\n",
        "\n",
        "        col_defs.sort()        \n",
        "        create_table = f'CREATE TABLE \"{table_name}\" (\\n' + \", \\n\".join(col_defs) + \"\\n)\"\n",
        "\n",
        "        table_info = f\"{create_table.rstrip()}\"\n",
        "            \n",
        "        # Add indexes if needed\n",
        "        if self._indexes_in_table_info:\n",
        "            table_info += \"\\n\\n/*\"\n",
        "            table_info += f\"\\n{self._get_table_indexes(table)}\\n\"\n",
        "            table_info += \"*/\"\n",
        "\n",
        "        return table_info\n",
        "\n",
        "\n",
        "    def _get_column_descriptions_from_metadata(\n",
        "        self, table_name: str\n",
        "    ) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Fetch column descriptions from the metadata EAV table created alongside the data table.\n",
        "\n",
        "        Expects a companion table named \"{table_name}__metadata\" with rows:\n",
        "            entity = column name\n",
        "            attribute = \"description\"\n",
        "            value = description text\n",
        "        \"\"\"\n",
        "        metadata_table = f\"{table_name}__metadata\"\n",
        "        if metadata_table not in self._all_tables:\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            query = text(\n",
        "                f'SELECT entity, value FROM \"{metadata_table}\" WHERE attribute = :attr'\n",
        "            )\n",
        "            with self._engine.connect() as connection:\n",
        "                result: Result = connection.execute(query, {\"attr\": \"description\"})\n",
        "                return {row[0]: row[1] for row in result if row[1] is not None}\n",
        "        except (ProgrammingError, SQLAlchemyError):\n",
        "            return {}\n",
        "\n",
        "\n",
        "    def get_column_groups(self, table_name: str) -> List[List[str]]:\n",
        "        \"\"\"\n",
        "        Return column groups for a table based on its metadata companion table.\n",
        "\n",
        "        Reads rows where attribute == \"group\" from \"{table_name}__metadata\" and\n",
        "        builds a list of column-name lists, ordered by group id.\n",
        "        \"\"\"\n",
        "        metadata_table = f\"{table_name}__metadata\"\n",
        "        if metadata_table not in self._all_tables:\n",
        "            return []\n",
        "\n",
        "        groups: Dict[int, List[str]] = {}\n",
        "        try:\n",
        "            query = text(\n",
        "                f'SELECT entity, value FROM \"{metadata_table}\" WHERE attribute = :attr'\n",
        "            )\n",
        "            with self._engine.connect() as connection:\n",
        "                result: Result = connection.execute(query, {\"attr\": \"group\"})\n",
        "                for entity, value in result:\n",
        "                    if value is None:\n",
        "                        continue\n",
        "                    try:\n",
        "                        group_id = int(value)\n",
        "                    except (TypeError, ValueError):\n",
        "                        continue\n",
        "                    groups.setdefault(group_id, []).append(entity)\n",
        "        except (ProgrammingError, SQLAlchemyError):\n",
        "            return []\n",
        "\n",
        "        if not groups:\n",
        "            return []\n",
        "\n",
        "        return [groups[idx] for idx in sorted(groups.keys())]\n",
        "\n",
        "\n",
        "    def _get_table_indexes(self, table: Table) -> str:\n",
        "        \"\"\"Get formatted index information for a table.\"\"\"\n",
        "        indexes = self._inspector.get_indexes(table.name)\n",
        "        indexes_formatted = \"\\n\".join(\n",
        "            f\"Name: {idx['name']}, Unique: {idx['unique']}, Columns: {idx['column_names']}\"\n",
        "            for idx in indexes\n",
        "        )\n",
        "        return f\"Table Indexes:\\n{indexes_formatted}\"\n",
        "\n",
        "\n",
        "    def _get_sample_values(\n",
        "        self,\n",
        "        table: Table,\n",
        "        columns: List[Column],\n",
        "        sample_count: int,\n",
        "    ) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Get up to sample_count distinct example values per column.\n",
        "\n",
        "        Strings are quoted to reflect their type. Values longer than 100 chars are skipped.\n",
        "        \"\"\"\n",
        "        if sample_count <= 0:\n",
        "            return {}\n",
        "\n",
        "        column_sample_values: Dict[str, List[str]] = {col.name: [] for col in columns}\n",
        "        for col in columns:\n",
        "            query = text(\n",
        "                f'SELECT DISTINCT \"{col.name}\" '\n",
        "                f'FROM \"{table.name}\" '\n",
        "                f'WHERE \"{col.name}\" IS NOT NULL '\n",
        "                f\"LIMIT {sample_count}\"\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                with self._engine.connect() as connection:\n",
        "                    result = connection.execute(query)\n",
        "                    remaining_length = 1000\n",
        "                    for val, in result:\n",
        "                        val_str = str(val)\n",
        "                        # Represent type: quote strings, leave others as-is\n",
        "                        display_val = f'\"{val_str}\"' if isinstance(val, str) else val_str\n",
        "                        column_sample_values[col.name].append(display_val)\n",
        "                        remaining_length -= len(display_val)\n",
        "                        if remaining_length <= 0:\n",
        "                            break\n",
        "\n",
        "            except ProgrammingError:\n",
        "                continue\n",
        "\n",
        "        return column_sample_values\n",
        "\n",
        "\n",
        "    def _execute(\n",
        "        self,\n",
        "        command: str,\n",
        "        fetch: Literal[\"all\", \"one\", \"cursor\"] = \"all\",\n",
        "        *,\n",
        "        parameters: Optional[Dict[str, Any]] = None,\n",
        "        execution_options: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Union[Sequence[Dict[str, Any]], Result]:\n",
        "        \"\"\"Execute SQL command through underlying engine.\"\"\"\n",
        "        parameters = parameters or {}\n",
        "        execution_options = execution_options or {}\n",
        "        \n",
        "        with self._engine.begin() as connection:\n",
        "            cursor = connection.execute(\n",
        "                text(command),\n",
        "                parameters,\n",
        "                execution_options=execution_options,\n",
        "            )\n",
        "\n",
        "            if cursor.returns_rows:\n",
        "                if fetch == \"all\":\n",
        "                    result = [x._asdict() for x in cursor.fetchall()]\n",
        "                elif fetch == \"one\":\n",
        "                    first_result = cursor.fetchone()\n",
        "                    result = [] if first_result is None else [first_result._asdict()]\n",
        "                elif fetch == \"cursor\":\n",
        "                    return cursor\n",
        "                else:\n",
        "                    raise ValueError(\"Fetch parameter must be either 'one', 'all', or 'cursor'\")\n",
        "                return result\n",
        "        return []\n",
        "\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        command: str,\n",
        "        fetch: Literal[\"all\", \"one\", \"cursor\"] = \"all\",\n",
        "        include_columns: bool = False,\n",
        "        *,\n",
        "        parameters: Optional[Dict[str, Any]] = None,\n",
        "        execution_options: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Union[Sequence[Dict[str, Any]], Sequence[Tuple[Any, ...]], Result[Any]]:\n",
        "        \"\"\"Execute a SQL command and return a string representing the results.\"\"\"\n",
        "        result = self._execute(\n",
        "            command, fetch, parameters=parameters, execution_options=execution_options\n",
        "        )\n",
        "\n",
        "        if fetch == \"cursor\":\n",
        "            return result\n",
        "\n",
        "        if include_columns:\n",
        "            return [\n",
        "                {\n",
        "                    column: truncate_word(value, length=self._max_string_length)\n",
        "                    for column, value in r.items()\n",
        "                }\n",
        "                for r in result\n",
        "            ]\n",
        "        else:\n",
        "            return [\n",
        "                tuple(\n",
        "                    truncate_word(value, length=self._max_string_length)\n",
        "                    for value in r.values()\n",
        "                )\n",
        "                for r in result\n",
        "            ]\n",
        "\n",
        "\n",
        "    def run_no_throw(\n",
        "        self,\n",
        "        command: str,\n",
        "        fetch: Literal[\"all\", \"one\"] = \"all\",\n",
        "        include_columns: bool = False,\n",
        "        *,\n",
        "        parameters: Optional[Dict[str, Any]] = None,\n",
        "        execution_options: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute a SQL command and return results or error message.\"\"\"\n",
        "        try:\n",
        "            res = self.run(\n",
        "                command,\n",
        "                fetch,\n",
        "                parameters=parameters,\n",
        "                execution_options=execution_options,\n",
        "                include_columns=include_columns,\n",
        "            )\n",
        "            return {\n",
        "                \"result\": res,\n",
        "                \"error\": None,\n",
        "            }\n",
        "        except SQLAlchemyError as e:\n",
        "            return {\n",
        "                \"result\": [],\n",
        "                \"error\": f\"Error: {e}\",\n",
        "            }\n",
        "\n",
        "\n",
        "    def get_table_info_no_throw(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        get_col_comments: bool = False,\n",
        "        allowed_col_names: Optional[List[str]] = None,\n",
        "        sample_count: Optional[int] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Get table info without throwing exceptions.\"\"\"\n",
        "        try:\n",
        "            return self.get_table_info(\n",
        "                table_name,\n",
        "                get_col_comments=get_col_comments,\n",
        "                allowed_col_names=allowed_col_names,\n",
        "                sample_count=sample_count,\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "    def get_context(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return db context that you may want in agent prompt.\"\"\"\n",
        "        table_names = list(self.get_usable_table_names())\n",
        "        # Get info for all tables\n",
        "        table_infos = []\n",
        "        for tbl in table_names:\n",
        "            table_infos.append(self.get_table_info_no_throw(tbl))\n",
        "        table_info = \"\\n\\n\".join(table_infos)\n",
        "        return {\"table_info\": table_info, \"table_names\": \", \".join(table_names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "id": "44b151e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "@lru_cache()\n",
        "def get_sqlite_db(business_name: str):\n",
        "    return SQLiteDatabase.from_uri(\n",
        "        f\"sqlite:////Users/vinhnguyen/Projects/ext-chatbot/resources/database/{business_name}.db\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "id": "05f79041",
      "metadata": {},
      "outputs": [],
      "source": [
        "db = get_sqlite_db(\"batdongsan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "id": "3b5e1acb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# db.run(\"\"\"\n",
        "# select * from \"BĐS Bán 500\" limit 5;\n",
        "# \"\"\", include_columns=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "id": "3bfc7513",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SQLite'"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.dialect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "id": "e27e57b8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BĐS Bán 500', 'BĐS Cho thuê 500']"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.get_usable_table_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "id": "353e271d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# db.get_column_groups(\"BĐS Bán 500\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "id": "c2b02da9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATE TABLE \"BĐS Bán 500\" (\n",
            "\t\"Bãi đỗ xe\" TEXT\t/* Thông tin về khả năng đỗ xe (bao gồm số lượng và loại phương tiện). Ví dụ: \"Có\", \"Không\", \"Nhiều xe máy\", \"1 ô tô\", \"2 ô tô\",... */, \n",
            "\t\"Chiều dài (m)\" REAL\t/* Độ dài chiều dài của bất động sản tính theo mét. Ví dụ: 3.9, 8.6, 16.4, 7.7, 32.6,... */\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(db.get_table_info_no_throw(\n",
        "    \"BĐS Bán 500\",\n",
        "    get_col_comments=True,\n",
        "    allowed_col_names=[\"Bãi đỗ xe\", \"Chiều dài (m)\"],\n",
        "    sample_count=5\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87fc0b38",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac33b2ff",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f7a7e0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26208608",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161630a6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "37598a24",
      "metadata": {},
      "source": [
        "# Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "e7b5375b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from pydantic import BaseModel, Field\n",
        "import functools\n",
        "# import asyncio\n",
        "from tqdm.asyncio import tqdm_asyncio\n",
        "\n",
        "from typing import Annotated\n",
        "from langchain_core.messages import AnyMessage\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.tools import tool\n",
        "from langchain.messages import SystemMessage\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "6be91324",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = get_llm_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ddf23d",
      "metadata": {},
      "source": [
        "## SQL Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0f6a4c",
      "metadata": {},
      "source": [
        "### Schema Linking Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59b6ad6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# table and column selection (run async for multi table / run one time for all tables)\n",
        "# tools: retrieve_values_in_columns, query_database, return_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "id": "e7c52bfd",
      "metadata": {},
      "outputs": [],
      "source": [
        "SCHEMA_LINKING_TEMPLATE = \"\"\"\n",
        "You are an expert in SQL schema linking. \n",
        "Given a {dialect} table schema (DDL) and a user query, determine if the table is relevant to the query.\n",
        "\n",
        "Your task:\n",
        "1. Analyze the table schema and the user query to decide if they are related.\n",
        "2. Answer \"Y\" (Yes) or \"N\" (No).\n",
        "3. If the answer is \"Y\", list ALL columns that are semantically related to the query topics. \n",
        "   - You do NOT need to identify the exact columns for the final SQL query. \n",
        "   - You SHOULD include any columns that provide context, identifiers, or potential join keys related to the entities in the query.\n",
        "\n",
        "Output must be a valid JSON object inside a ```json code block using this format:\n",
        "```json\n",
        "{{\n",
        "    \"think\": \"Brief reasoning step by step\",\n",
        "    \"is_related\": \"Y or N\",\n",
        "    \"columns\": [\"column name 1\", \"column name 2\"]\n",
        "}}\n",
        "```\n",
        "\n",
        "Table Schema (DDL):\n",
        "{table_info}\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\"\"\".strip()\n",
        "\n",
        "schema_linking_chain = (\n",
        "    ChatPromptTemplate([(\"human\", SCHEMA_LINKING_TEMPLATE)])\n",
        "    | llm\n",
        "    | JsonOutputParser()\n",
        ")\n",
        "\n",
        "async def _link_schema_one(\n",
        "    query: str,\n",
        "    table_name: str,\n",
        "    allowed_col_names: Optional[List[str]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    try:\n",
        "        table_info = db.get_table_info_no_throw(\n",
        "            table_name,\n",
        "            get_col_comments=True,\n",
        "            allowed_col_names=allowed_col_names,\n",
        "            sample_count=3\n",
        "        )\n",
        "        result = await schema_linking_chain.ainvoke(\n",
        "            {\"table_info\": table_info, \"query\": query, \"dialect\": db.dialect}\n",
        "        )\n",
        "        if \"is_related\" not in result or result[\"is_related\"] not in [\"Y\", \"N\"]:\n",
        "            raise ValueError(\"Invalid response from schema linking chain\")\n",
        "        if result[\"is_related\"] == \"Y\" and not result.get(\"columns\"):\n",
        "            result[\"columns\"] = [\"ROWID\"]\n",
        "\n",
        "        if result[\"is_related\"] == \"N\":\n",
        "            return {\n",
        "                \"input_item\": {\n",
        "                    \"table_name\": table_name,\n",
        "                    \"query\": query,\n",
        "                    \"allowed_col_names\": allowed_col_names\n",
        "                },\n",
        "                \"filtered_schema\": None,\n",
        "                \"error\": None\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"input_item\": {\"table_name\": table_name, \"query\": query, \"allowed_col_names\": allowed_col_names},\n",
        "                \"filtered_schema\": (table_name, result[\"columns\"]),\n",
        "                \"error\": None\n",
        "            }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"input_item\": {\"table_name\": table_name, \"query\": query},\n",
        "            \"filtered_schema\": None,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "async def link_schema(\n",
        "    _input: dict,\n",
        ") -> Dict[str, Dict[str, str]]:\n",
        "    query = _input.get(\"query\")\n",
        "    if not query:\n",
        "        raise ValueError(\"query is required\")\n",
        "    max_retries = _input.get(\"max_retries\", 1)\n",
        "    # queue = []\n",
        "    # for table in  db.get_usable_table_names():\n",
        "    #     for col_group in db.get_column_groups(table):\n",
        "    #         queue.append({\n",
        "    #             \"table_name\": table,\n",
        "    #             \"allowed_col_names\": col_group,\n",
        "    #             \"query\": query\n",
        "    #         })\n",
        "    queue = [{\"table_name\": table_name, \"query\": query} for table_name in db.get_usable_table_names()]\n",
        "    successful_results = []\n",
        "    for _ in range(max_retries):\n",
        "        tasks = [_link_schema_one(**input_item) for input_item in queue]\n",
        "        results = await tqdm_asyncio.gather(*tasks)\n",
        "        successful_results.extend([\n",
        "            res for res in results if res[\"error\"] is None\n",
        "        ])\n",
        "        failed_items = [\n",
        "            res[\"input_item\"] for res in results if res[\"error\"] is not None\n",
        "        ]\n",
        "        queue = failed_items\n",
        "        if not queue:\n",
        "            break\n",
        "    \n",
        "    linked_schemas = [\n",
        "        result[\"filtered_schema\"] for result in successful_results if result[\"filtered_schema\"]\n",
        "    ]\n",
        "\n",
        "    # Return per-table mapping: column_name -> datatype\n",
        "    final_schemas: Dict[str, Dict[str, str]] = {}\n",
        "    for table_name, col_names in linked_schemas:\n",
        "        table_schema = final_schemas.setdefault(table_name, {})\n",
        "        for col_name in col_names:\n",
        "            col_type = db.get_column_datatype(\n",
        "                table_name,\n",
        "                col_name,\n",
        "                default=\"NULL\",\n",
        "            )\n",
        "            if col_type != \"NULL\":\n",
        "                table_schema[col_name] = col_type\n",
        "\n",
        "    return final_schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "id": "dffb8b2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'BĐS Bán 500': {'Địa chỉ_Tên đường': 'TEXT', 'Địa chỉ': 'TEXT'},\n",
              " 'BĐS Cho thuê 500': {'Địa chỉ': 'TEXT', 'Địa chỉ_đường': 'TEXT'}}"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Tìm danh sách nhà cho thuê ở trên đường Láng\"\n",
        "linked_schemas = await link_schema({\"query\": query})\n",
        "linked_schemas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ffda9d",
      "metadata": {},
      "source": [
        "### SQL Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "id": "c9638605",
      "metadata": {},
      "outputs": [],
      "source": [
        "SQL_AGENT_PROMPT_TEMPLATE = \"\"\"\n",
        "### DATE INFORMATION:\n",
        "Today is {date}\n",
        "\n",
        "### INSTRUCTIONS:\n",
        "You write SQL queries for a {dialect} database. Users are querying their company database, and your task is to assist by generating valid SQL queries strictly adhering to the database schema provided.\n",
        "\n",
        "**Table Schema**:\n",
        "{table_infos}\n",
        "\n",
        "Translate the user's request into one valid {dialect} query. SQL should be written as a markdown code block:\n",
        "For example:\n",
        "```sql\n",
        "SELECT * FROM table WHERE condition;\n",
        "```\n",
        "\n",
        "### GUIDELINES:\n",
        "\n",
        "1.  **Schema Adherence**:\n",
        "    *   Use only tables, columns, and relationships explicitly listed in the provided schema.\n",
        "    *   Do not make assumptions about missing or inferred columns/tables.\n",
        "\n",
        "2.  **{dialect}-Specific Syntax**:\n",
        "    *   Use only {dialect} syntax. Be aware that {dialect} has limited built-in date/time functions compared to other sql dialects.\n",
        "\n",
        "3.  **Conditions**:\n",
        "    *   Always include default conditions for filtering invalid data, e.g., `deleted_at IS NULL` and `status != 'cancelled'` if relevant.\n",
        "    *   Ensure these conditions match the query's intent unless explicitly omitted in the user request.\n",
        "\n",
        "4.  **Output Consistency**:\n",
        "    *   The output fields must match the query's intent exactly. Do not add extra columns or omit requested fields.\n",
        "\n",
        "5.  **Reserved Keywords and Case Sensitivity**:\n",
        "    *   Escape reserved keywords or case-sensitive identifiers using double quotes (\" \"), e.g., \"order\".\n",
        "\n",
        "If the user's question is ambiguous or unclear, you must make your best reasonable guess based on the schema.\n",
        "Translate the user's intent into a **single valid {dialect} query** based on the schema provided.\n",
        "Ensure the query is optimized, precise, and error-free.\n",
        "\n",
        "**You must ONLY output ONE SINGLE valid SQL query as markdown codeblock.**\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "id": "a257bda9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "_sql_markdown_re = re.compile(r\"```sql\\s*([\\s\\S]*?)\\s*```\", re.DOTALL)\n",
        "\n",
        "\n",
        "def parse_sql_output(msg_content: str) -> str:\n",
        "    try:\n",
        "        match = _sql_markdown_re.search(msg_content)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        else:\n",
        "            raise ValueError(\"No SQL query found in the content\")\n",
        "    except Exception:\n",
        "        return msg_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "id": "4133f013",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "def preprocess_for_sql_query_generation(\n",
        "    _input: dict,\n",
        ") -> List[AnyMessage]:\n",
        "    linked_schemas: Dict[str, Dict[str, str]] = _input.get(\"linked_schemas\")\n",
        "    if not linked_schemas:\n",
        "        raise ValueError(\"linked_schemas not found in the input\")\n",
        "    table_infos = \"\\n\".join([\n",
        "        db.get_table_info_no_throw(\n",
        "            table_name,\n",
        "            get_col_comments=True,\n",
        "            allowed_col_names=list(col_types.keys()),\n",
        "            sample_count=5,\n",
        "        )\n",
        "        for table_name, col_types in linked_schemas.items()\n",
        "    ])\n",
        "    system_prompt = SystemMessage(SQL_AGENT_PROMPT_TEMPLATE.format(\n",
        "        table_infos=table_infos,\n",
        "        date=get_today_date_en(),\n",
        "        dialect=db.dialect\n",
        "    ))\n",
        "    human_message = HumanMessage(content=_input[\"query\"])\n",
        "    return [system_prompt, human_message]\n",
        "\n",
        "\n",
        "def get_sql_query_from_content(content: str) -> str:\n",
        "    sql_block_pattern = re.compile(r\"```sql\\s*([\\s\\S]*?)\\s*```\", re.MULTILINE)\n",
        "    match = sql_block_pattern.search(content)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    else:\n",
        "        raise ValueError(\"No SQL query found in the content\")\n",
        "\n",
        "sql_query_generation_chain = (\n",
        "    preprocess_for_sql_query_generation\n",
        "    | get_llm_model()\n",
        "    | StrOutputParser()\n",
        "    | parse_sql_output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "id": "54f5697e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT \"Địa chỉ\" \n",
            "FROM \"BĐS Cho thuê 500\" \n",
            "WHERE \"Địa chỉ_đường\" = \"Láng\" OR \"Địa chỉ_đường\" = \"Cầu Giấy\";\n"
          ]
        }
      ],
      "source": [
        "print(sql_query_generation_chain.invoke({\n",
        "    \"query\": \"Tìm danh sách nhà cho thuê ở trên đường Láng hoặc Cầu Giấy\",\n",
        "    \"linked_schemas\": linked_schemas\n",
        "}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02801d6e",
      "metadata": {},
      "source": [
        "### SQL Chain without Retry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "id": "20acb415",
      "metadata": {},
      "outputs": [],
      "source": [
        "sql_chain_without_retry = RunnablePassthrough.assign(\n",
        "    linked_schemas=link_schema\n",
        ") | RunnablePassthrough.assign(\n",
        "    sql_query=sql_query_generation_chain\n",
        ") | RunnablePassthrough.assign(\n",
        "    db_output=lambda _input: db.run_no_throw(\n",
        "        _input[\"sql_query\"],\n",
        "        include_columns=True\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "id": "caf21465",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"query\": \"Tìm danh sách nhà cho thuê ở trên đường Láng hoặc Cầu Giấy\",\n",
            "  \"linked_schemas\": {\n",
            "    \"BĐS Bán 500\": {\n",
            "      \"Địa chỉ_Tên đường\": \"TEXT\",\n",
            "      \"Địa chỉ\": \"TEXT\"\n",
            "    },\n",
            "    \"BĐS Cho thuê 500\": {\n",
            "      \"Địa chỉ\": \"TEXT\",\n",
            "      \"Địa chỉ_đường\": \"TEXT\"\n",
            "    }\n",
            "  },\n",
            "  \"sql_query\": \"SELECT \\\"Địa chỉ\\\" \\nFROM \\\"BĐS Cho thuê 500\\\" \\nWHERE \\\"Địa chỉ_đường\\\" IN ('Láng', 'Cầu Giấy');\",\n",
            "  \"db_output\": {\n",
            "    \"result\": [],\n",
            "    \"error\": null\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "_output = await sql_chain_without_retry.ainvoke({\n",
        "    \"query\": \"Tìm danh sách nhà cho thuê ở trên đường Láng hoặc Cầu Giấy\",\n",
        "})\n",
        "print(json.dumps(_output, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e562b35",
      "metadata": {},
      "source": [
        "### Parse SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9652cd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlglot import exp, parse_one\n",
        "\n",
        "\n",
        "def get_column_value_pairs(\n",
        "    sql_query: str, schema: Dict[str, Dict[str, str]]\n",
        "):\n",
        "    parsed = parse_one(sql_query, read=db.dialect.lower())\n",
        "    \n",
        "    # --- Step A: Resolve Aliases (c -> customers) ---\n",
        "    alias_map = {}\n",
        "    \n",
        "    # 1. Check FROM\n",
        "    for node in parsed.find_all(exp.From):\n",
        "        for table in node.find_all(exp.Table):\n",
        "            real_name = table.name\n",
        "            alias = table.alias if table.alias else real_name\n",
        "            alias_map[alias] = real_name\n",
        "\n",
        "    # 2. Check JOINs\n",
        "    for node in parsed.find_all(exp.Join):\n",
        "        table = node.this\n",
        "        real_name = table.name\n",
        "        alias = table.alias if table.alias else real_name\n",
        "        alias_map[alias] = real_name\n",
        "\n",
        "    print(f\"DEBUG: Found Aliases: {alias_map}\")\n",
        "\n",
        "    extracted_data = []\n",
        "\n",
        "    # --- Step B: Recursive Visitor ---\n",
        "    def visit_node(node):\n",
        "        if not node:\n",
        "            return\n",
        "\n",
        "        # 1. Handle Binary Logic (AND, OR)\n",
        "        # sqlglot stores left side in 'this' and right side in 'expression'\n",
        "        if isinstance(node, (exp.And, exp.Or)):\n",
        "            visit_node(node.this)\n",
        "            visit_node(node.expression)\n",
        "            return\n",
        "\n",
        "        # 2. Handle Wrappers (Parenthesis, NOT, WHERE)\n",
        "        # These only have one child stored in 'this'\n",
        "        if isinstance(node, (exp.Paren, exp.Not, exp.Where)):\n",
        "            visit_node(node.this)\n",
        "            return\n",
        "\n",
        "        # 3. Handle Comparisons (Column = 'Value', !=, LIKE)\n",
        "        if isinstance(node, (exp.EQ, exp.NEQ, exp.Like, exp.ILike)):\n",
        "            # We look for: Column op Literal\n",
        "            if isinstance(node.left, exp.Column) and isinstance(node.right, exp.Literal):\n",
        "                if node.right.is_string:\n",
        "                    process_extraction(node.left, node.right.this, node.key)\n",
        "            return\n",
        "\n",
        "        # 4. Handle IN (Column IN ('A', 'B'))\n",
        "        if isinstance(node, exp.In):\n",
        "            if isinstance(node.this, exp.Column):\n",
        "                # The list of values is in args['expressions']\n",
        "                for item in node.args.get('expressions', []):\n",
        "                    if isinstance(item, exp.Literal) and item.is_string:\n",
        "                        process_extraction(node.this, item.this, \"IN\")\n",
        "            return\n",
        "\n",
        "    # Helper to validate and store\n",
        "    def process_extraction(col_node, value_str, operator):\n",
        "        col_name = col_node.name\n",
        "        table_alias = col_node.table\n",
        "        \n",
        "        real_table_name = None\n",
        "\n",
        "        # Resolve Alias\n",
        "        if table_alias:\n",
        "            real_table_name = alias_map.get(table_alias)\n",
        "        else:\n",
        "            # Try to guess table from schema if no alias provided\n",
        "            matches = [t for t, cols in schema.items() if col_name in cols]\n",
        "            if len(matches) == 1:\n",
        "                real_table_name = matches[0]\n",
        "\n",
        "        # Validation\n",
        "        if real_table_name and real_table_name in schema:\n",
        "            cols = schema[real_table_name]\n",
        "            if col_name in cols:\n",
        "                if cols[col_name] == \"TEXT\":\n",
        "                    extracted_data.append({\n",
        "                        \"table\": real_table_name,\n",
        "                        \"column\": col_name,\n",
        "                        \"original_value\": value_str,\n",
        "                        \"operator\": operator\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"DEBUG: Skipped {col_name} (Not TEXT)\")\n",
        "            else:\n",
        "                print(f\"DEBUG: Skipped {col_name} (Not in {real_table_name})\")\n",
        "        else:\n",
        "            print(f\"DEBUG: Skipped {col_name} (Unknown table/alias)\")\n",
        "\n",
        "    # --- Step C: Start Traversal ---\n",
        "    where_clause = parsed.find(exp.Where)\n",
        "    if where_clause:\n",
        "        # Crucial Fix: Pass where_clause.this (the content) OR rely on the updated visitor handling exp.Where\n",
        "        visit_node(where_clause)\n",
        "    \n",
        "    return extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100f8c61",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Found Aliases: {'c': 'customers', 'o': 'orders', 'p': 'products'}\n",
            "DEBUG: Skipped full_name (Unknown table/alias)\n",
            "\n",
            "--- FINAL EXTRACTED PAIRS FOR VECTOR SEARCH ---\n",
            "{'table': 'customers', 'column': 'country', 'original_value': 'USA', 'operator': 'IN'}\n",
            "{'table': 'customers', 'column': 'country', 'original_value': 'Canada', 'operator': 'IN'}\n",
            "{'table': 'customers', 'column': 'country', 'original_value': 'UK', 'operator': 'IN'}\n",
            "{'table': 'customers', 'column': 'country', 'original_value': 'Germany', 'operator': 'IN'}\n",
            "{'table': 'orders', 'column': 'status', 'original_value': 'Cancelled', 'operator': 'neq'}\n",
            "{'table': 'products', 'column': 'category', 'original_value': 'Electronics', 'operator': 'eq'}\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. SETUP\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "SQL_QUERY = \"\"\"\n",
        "SELECT c.id, c.first_name || ' ' || c.last_name AS full_name \n",
        "FROM customers c\n",
        "INNER JOIN orders o ON c.id = o.customer_id\n",
        "INNER JOIN products p ON o.product_id = p.id\n",
        "WHERE \n",
        "    c.country IN ('USA', 'Canada', 'UK', 'Germany')\n",
        "    AND o.order_date BETWEEN '2023-01-01' AND '2023-12-31'\n",
        "    AND o.status != 'Cancelled'\n",
        "    AND p.category = 'Electronics'\n",
        "    AND full_name = 'David Jones' \n",
        "\"\"\"\n",
        "\n",
        "DB_SCHEMA = {\n",
        "    \"customers\": {\"id\": \"INTEGER\", \"first_name\": \"TEXT\", \"last_name\": \"TEXT\", \"country\": \"TEXT\"},\n",
        "    \"orders\": {\"id\": \"INTEGER\", \"customer_id\": \"INTEGER\", \"order_date\": \"TEXT\", \"status\": \"TEXT\"},\n",
        "    \"products\": {\"id\": \"INTEGER\", \"product_name\": \"TEXT\", \"category\": \"TEXT\"}\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. ROBUST PARSER LOGIC\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. EXECUTION\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "results = get_column_value_pairs(SQL_QUERY, DB_SCHEMA)\n",
        "\n",
        "print(\"\\n--- FINAL EXTRACTED PAIRS FOR VECTOR SEARCH ---\")\n",
        "for res in results:\n",
        "    print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f0a664",
      "metadata": {},
      "source": [
        "### Retry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "id": "96e38626",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT \"Địa chỉ\" \n",
            "FROM \"BĐS Cho thuê 500\" \n",
            "WHERE \"Địa chỉ_đường\" IN ('Láng', 'Cầu Giấy');\n"
          ]
        }
      ],
      "source": [
        "print(_output[\"sql_query\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "id": "df59fc73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Found Aliases: {'BĐS Cho thuê 500': 'BĐS Cho thuê 500'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'table': 'BĐS Cho thuê 500',\n",
              "  'column': 'Địa chỉ_đường',\n",
              "  'original_value': 'Láng',\n",
              "  'operator': 'IN'},\n",
              " {'table': 'BĐS Cho thuê 500',\n",
              "  'column': 'Địa chỉ_đường',\n",
              "  'original_value': 'Cầu Giấy',\n",
              "  'operator': 'IN'}]"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_column_value_pairs(_output[\"sql_query\"], _output[\"linked_schemas\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe28398b",
      "metadata": {},
      "source": [
        "## Orchestrator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "id": "72407583",
      "metadata": {},
      "outputs": [],
      "source": [
        "ORCHESTRATOR_PROMPT = \"\"\"\n",
        "Bạn là một trợ lý ảo chuyên trả lời các câu hỏi về thị trường bất động sản dựa trên một bộ dữ liệu nội bộ. Cơ sở dữ liệu này bao gồm danh sách các bất động sản bán và cho thuê. Khi người dùng hỏi về các chủ đề này, nhiệm vụ của bạn là gọi một trợ lý ảo khác (SQL Assistant) và đưa ra mệnh lệnh (bằng ngôn ngữ tự nhiên) để trợ lý ảo thực hiện viết câu truy vấn và thu thập thông tin liên quan. Đối với các câu hỏi nằm ngoài lĩnh vực bất động sản này, hãy sử dụng kiến thức của bạn để trả lời trực tiếp.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "class SQLAssistantInput(BaseModel):\n",
        "    command: str = Field(description=\"The command in natural language\")\n",
        "\n",
        "\n",
        "@tool(\"call_sql_assistant\",args_schema=SQLAssistantInput)\n",
        "def call_sql_assistant(command: str) -> str:\n",
        "    \"\"\"Call the SQL Assistant to get the information\"\"\"\n",
        "    return \"Hello, world!\"\n",
        "\n",
        "\n",
        "orchestrator_chain = RunnablePassthrough.assign(\n",
        "    messages=functools.partial(\n",
        "        preprocess_messages, system_prompt=ORCHESTRATOR_PROMPT)\n",
        "    | get_llm_model().bind_tools([call_sql_assistant])\n",
        "    | postprocess_ai_message\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "id": "92f31acf",
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"orchestrator\", orchestrator_chain)\n",
        "builder.add_edge(START, \"orchestrator\")\n",
        "builder.add_edge(\"orchestrator\", END)\n",
        "\n",
        "orchestrator = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "9a822823",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Hello' additional_kwargs={} response_metadata={} id='6d1829d8-cd90-43bc-b70d-e36cc5bdb439'\n",
            "content='' additional_kwargs={} response_metadata={} id='69ab6696-aa2e-4bb4-a670-7a49dfae2414' tool_calls=[{'name': 'call_sql_assistant', 'args': {}, 'id': '1', 'type': 'tool_call'}]\n",
            "Time taken: 0.5081579685211182 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "state = orchestrator.invoke({\"messages\": [\n",
        "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
        "    # {\"role\": \"user\", \"content\": \"Hello, hôm qua ngày bao nhiêu nhể\"},\n",
        "    # {\"role\": \"assistant\", \"content\": \"Hôm qua là ngày 13 tháng 12 năm 2025\"},\n",
        "    # {\"role\": \"user\", \"content\": \"Có bao nhiêu nhà đang được cho thuê nhỉ\"}\n",
        "    # {\"role\": \"user\", \"content\": \"1 + 2 + 3 + ... + 100 = ?\"}\n",
        "]})\n",
        "for message in state[\"messages\"]:\n",
        "    print(message)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d7f1e8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "extchatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
