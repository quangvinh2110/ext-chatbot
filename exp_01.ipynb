{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d241c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from functools import lru_cache\n",
    "from typing import List, Any\n",
    "import numpy as np\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import InfinityEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "from src.utils import load_env\n",
    "from src.parser import ExcelParser\n",
    "from src.processor import TableProcessor\n",
    "from src.prompts import (\n",
    "    EXTRACT_STRUCTURE_TEMPLATE,\n",
    "    TRANSFORM_DATA_TEMPLATE\n",
    ")\n",
    "\n",
    "load_env(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e306567",
   "metadata": {},
   "source": [
    "# Setup components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89608e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_BASE_URL=os.getenv(\"LLM_BASE_URL\")\n",
    "LLM_MODEL=os.getenv(\"LLM_MODEL\")\n",
    "LLM_API_KEY=os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "EMBED_BASE_URL=os.getenv(\"EMBED_BASE_URL\")\n",
    "EMBED_MODEL=os.getenv(\"EMBED_MODEL\")\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def get_llm_model():\n",
    "    return ChatOpenAI(\n",
    "        model=LLM_MODEL,\n",
    "        base_url=LLM_BASE_URL,\n",
    "        api_key=LLM_API_KEY,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        presence_penalty=1,\n",
    "        extra_body = {\n",
    "            'chat_template_kwargs': {'enable_thinking': False},\n",
    "            \"top_k\": 20,\n",
    "            \"mip_p\": 0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "@lru_cache()\n",
    "def get_thinking_llm_model():\n",
    "    return ChatOpenAI(\n",
    "        model=LLM_MODEL,\n",
    "        base_url=LLM_BASE_URL,\n",
    "        api_key=LLM_API_KEY,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        presence_penalty=1,\n",
    "        extra_body = {\n",
    "            'chat_template_kwargs': {'enable_thinking': True},\n",
    "            \"top_k\": 20,\n",
    "            \"mip_p\": 0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "@lru_cache()\n",
    "def get_embedding_model():\n",
    "    return InfinityEmbeddings(\n",
    "        model=EMBED_MODEL,\n",
    "        infinity_api_url=EMBED_BASE_URL,\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def get_vector_store():\n",
    "    client = QdrantClient(\n",
    "        url=\"http://localhost\",\n",
    "        grpc_port=6334,\n",
    "        prefer_grpc=True,\n",
    "    )\n",
    "    embedding_model = get_embedding_model()\n",
    "    client.create_collection(\n",
    "        collection_name=\"demo\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=len(embedding_model.embed_query(\"Hello\")), \n",
    "            distance=Distance.COSINE\n",
    "        ),\n",
    "    )\n",
    "    return QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=\"demo\",\n",
    "        embedding=embedding_model,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecab7f",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d88dd",
   "metadata": {},
   "source": [
    "## Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368e3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 2: Found 1 tables\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Process multiple sheets\n",
    "file_path = \"/Users/vinhnguyen/Projects/Chatbot_code/DATA_hokkaido/data_raw/hokkaido_sachi_data_final.xlsx\"\n",
    "# file_path = \"/Users/vinhnguyen/Projects/ext-chatbot/resources/aaai-26.xlsx\"\n",
    "\n",
    "\n",
    "all_sheets_data = {}\n",
    "\n",
    "with ExcelParser(file_path) as parser:\n",
    "    # Parse each sheet (you can get sheet names from openpyxl if needed)\n",
    "    for sheet_idx in range(2, 4):  # or use sheet names\n",
    "        try:\n",
    "            tables = parser.parse_sheet(sheet_name=sheet_idx)\n",
    "            all_sheets_data[f\"Sheet_{sheet_idx}\"] = tables\n",
    "            print(f\"Sheet {sheet_idx}: Found {len(tables)} tables\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not parse sheet {sheet_idx}: {e}\")\n",
    "        finally:\n",
    "            break\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0f6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableInfo(data=array([['Khu vực', 'Tên Chi nhánh', 'Địa chỉ', 'Giờ mở cửa', 'Hotline'],\n",
       "       ['Hồ Chí Minh', 'Nguyễn Trãi',\n",
       "        '139 A-B Nguyễn Trãi, Phường Bến Thành, TP.HCM', '10:30-23:00',\n",
       "        '028 3926 0748 | 028 3926 0749'],\n",
       "       ['Hồ Chí Minh', 'Đông Du',\n",
       "        '40-42-44 Đông Du, Phường Sài Gòn, TP.HCM', '10:30-23:00 ',\n",
       "        '028 3822 5396 | 028 3822 5397'],\n",
       "       ['Hồ Chí Minh', 'Saigon Centre',\n",
       "        'Lầu 5 (L5-16,17) Saigon Centre, 67 Lê Lợi, Phường Sài Gòn, TP.HCM',\n",
       "        '10:30-22:00', '028 3821 8944 | 028 3535 8922'],\n",
       "       ['Hồ Chí Minh', 'Nguyễn Đình Chiểu',\n",
       "        '172 H-Q Nguyễn Đình Chiểu, Phường Xuân Hòa, TP.HCM',\n",
       "        '10:30-23:00', '028 3930 8355 | 028 3930 8366'],\n",
       "       ['Hồ Chí Minh', 'Pasteur', '180 Pasteur, Phường Sài Gòn, TP.HCM',\n",
       "        '10:30-23:00', '028 3823 2275 | 028 3823 2557'],\n",
       "       ['Hồ Chí Minh', 'Phan Xích Long',\n",
       "        '163 Phan Xích Long, Phường Cầu Kiệu, TP.HCM', '10:30-23:00',\n",
       "        '028 3636 7327 | 028 3636 7325'],\n",
       "       ['Hồ Chí Minh', 'Vincom Center Đồng Khởi',\n",
       "        'Tầng B3 (B3-07) Vincom Center Đồng Khởi, 72 Lê Thánh Tôn, Phường Sài Gòn, TP.HCM',\n",
       "        '10:30-22:00', '028 3823 5935 | 028 3823 5936'],\n",
       "       ['Hồ Chí Minh', 'Crescent Mall',\n",
       "        'Tầng Trệt (GF-28, 29B) Crescent Mall, 101 Tôn Dật Tiên, Phường Tân Mỹ, TP.HCM',\n",
       "        '10:30-22:30', '028 35151888 | 028 35151999'],\n",
       "       ['Hồ Chí Minh', 'Estella Place',\n",
       "        'Lầu 2 (L2-05, 06) Estella Place, 88 Song Hành, Phường Bình Trưng, TP.HCM',\n",
       "        '10:30-22:00', '028 3519 3388 | 028 3519 3377'],\n",
       "       ['Hồ Chí Minh', 'Hùng Vương Plaza',\n",
       "        'Lầu 4 (4F-04, 05) Hùng Vương Plaza, 126 Hồng Bàng, Phường Chợ Lớn, TP.HCM.',\n",
       "        '10:30-22:00', '028 3955 0777 | 028 3955 0666'],\n",
       "       ['Hồ Chí Minh', 'Thảo Điền',\n",
       "        'Sachi Garden, 109 Võ Nguyên Giáp, Phường An Khánh, TP.HCM.',\n",
       "        '10:30-23:00', '028 3620 2993 | 028 3620 2995'],\n",
       "       ['Hà Nội', 'Trần Hưng Đạo Hà Nội',\n",
       "        '33 Trần Hưng Đạo, Phường Cửa Nam, Hà Nội', '10:30-23:00',\n",
       "        '024 3838 8988 | 024 3238 3988'],\n",
       "       ['Hà Nội', 'Vincom Metropolis Liễu Giai Hà Nội',\n",
       "        'Lầu 3 (L3-05) Vincom Center Metropolis, 29 Liễu Giai, Phường Ngọc Hà, Hà Nội',\n",
       "        '10:30-22:00', '024 3312 0288 | 024 3312 0289'],\n",
       "       ['Hà Nội', 'Lotte Mall Tây Hồ Hà Nội',\n",
       "        'Lầu 3 (3F-321) Lotte Mall West Lake Hanoi, 272 Võ Chí Công, Phường Hồng Hà, Hà Nội.',\n",
       "        '10:30-22:00 - Last order: 21:30',\n",
       "        '024 3202 2936 | 024 3202 2938']], dtype=object), start_row=1, end_row=15, start_col=0, num_cols=5, num_data_rows=14, merged_cells=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c5b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_processor = TableProcessor(max_concurrent_requests=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa43a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting table structure...\n",
      "Transforming data...\n",
      "Attempt 1/5: Processing 14 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming data: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "result_dict = await table_processor(tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fcc3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table_structure': {'header_indices': [0], 'footer_indices': None},\n",
       " 'pydantic_schema': {'title': 'RowData',\n",
       "  'type': 'object',\n",
       "  'properties': {'khu_vuc': {'type': 'string',\n",
       "    'description': 'Region (e.g., Ho Chi Minh, Hanoi)'},\n",
       "   'ten_chi_nhanh': {'type': 'string', 'description': 'Branch name'},\n",
       "   'dia_chi': {'type': 'string', 'description': 'Full address details'},\n",
       "   'gio_mo_cua': {'type': 'string',\n",
       "    'description': 'Opening hours in HH:MM format'},\n",
       "   'hotline_1': {'type': 'string', 'description': 'Primary phone number'},\n",
       "   'hotline_2': {'type': 'string', 'description': 'Secondary phone number'}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"structure_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a73d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Nguyễn Trãi',\n",
       "  'dia_chi': '139 A-B Nguyễn Trãi, Phường Bến Thành, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3926 0748',\n",
       "  'hotline_2': '028 3926 0749'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Đông Du',\n",
       "  'dia_chi': '40-42-44 Đông Du, Phường Sài Gòn, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3822 5396',\n",
       "  'hotline_2': '028 3822 5397'},\n",
       " {'khu_vuc': 'Khu vực',\n",
       "  'ten_chi_nhanh': 'Tên Chi nhánh',\n",
       "  'dia_chi': 'Địa chỉ',\n",
       "  'gio_mo_cua': 'Giờ mở cửa',\n",
       "  'hotline_1': 'Hotline'},\n",
       " {'khu_vuc': 'Hà Nội',\n",
       "  'ten_chi_nhanh': 'Nguyễn Đình Chiểu',\n",
       "  'dia_chi': '172 H-Q Nguyễn Đình Chiểu, Phường Xuân Hòa, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3930 8355',\n",
       "  'hotline_2': '028 3930 8366'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Pasteur',\n",
       "  'dia_chi': '180 Pasteur, Phường Sài Gòn, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3823 2275',\n",
       "  'hotline_2': '028 3823 2557'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Phan Xích Long',\n",
       "  'dia_chi': '163 Phan Xích Long, Phường Cầu Kiệu, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3636 7327',\n",
       "  'hotline_2': '028 3636 7325'},\n",
       " {'khu_vuc': 'Khu vực',\n",
       "  'ten_chi_nhanh': 'Tên Chi nhánh',\n",
       "  'dia_chi': 'Địa chỉ',\n",
       "  'gio_mo_cua': 'Giờ mở cửa',\n",
       "  'hotline_1': 'Hotline'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Crescent Mall',\n",
       "  'dia_chi': 'Tầng Trệt (GF-28, 29B) Crescent Mall, 101 Tôn Dật Tiên, Phường Tân Mỹ, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-22:30',\n",
       "  'hotline_1': '028 35151888',\n",
       "  'hotline_2': '0987654321'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Estella Place',\n",
       "  'dia_chi': 'Lầu 2 (L2-05, 06) Estella Place, 88 Song Hành, Phường Bình Trưng, TP.HCM',\n",
       "  'gio_mo_cua': '10:30-22:00',\n",
       "  'hotline_1': '028 3519 3388',\n",
       "  'hotline_2': '028 3519 3519 3519 3377'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Hùng Vương Plaza',\n",
       "  'dia_chi': 'Lầu 4 (4F-04, 05) Hùng Vương Plaza, 126 Hồng Bàng, Phường Chợ Lớn, TP.HCM.',\n",
       "  'gio_mo_cua': '10:30-22:00',\n",
       "  'hotline_1': '028 3955 0777',\n",
       "  'hotline_2': '028 39555 0666'},\n",
       " {'khu_vuc': 'Hồ Chí Minh',\n",
       "  'ten_chi_nhanh': 'Thảo Điền',\n",
       "  'dia_chi': 'Sachi Garden, 109 Võ Nguyên Giáp, Phường An Khánh, TP.HCM.',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '028 3620 2993',\n",
       "  'hotline_2': '028 3620 2995'},\n",
       " {'khu_vuc': 'Hà Nội',\n",
       "  'ten_chi_nhanh': 'Trần Hưng Đạo Hà Nội',\n",
       "  'dia_chi': '33 Trần Hưng Đạo, Phường Cửa Nam, Hà Nội',\n",
       "  'gio_mo_cua': '10:30-23:00',\n",
       "  'hotline_1': '024 3838 8988',\n",
       "  'hotline_2': '024 3238 3988'},\n",
       " {'khu_vuc': 'Hà Nội',\n",
       "  'ten_chi_nhanh': 'Vincom Metropolis Liễu Giai Hà Nội',\n",
       "  'dia_chi': 'Lầu 3 (L3-05) Vincom Center Metropolis, 29 Liễu Giai, Phường Ngọc Hà, Hà Nội',\n",
       "  'gio_mo_cua': '10:30-22:00',\n",
       "  'hotline_1': '024 3312 0288',\n",
       "  'hotline_2': '024 3312 0288'},\n",
       " {'khu_vuc': 'value1',\n",
       "  'ten_chi_nhanh': 'value2',\n",
       "  'dia_chi': 'value3',\n",
       "  'gio_mo_cua': 'value4',\n",
       "  'hotline_1': 'value5',\n",
       "  'hotline_2': 'value6'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"transformed_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e075d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc5ed49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_table_data_snippet(\n",
    "    table_data: np.ndarray,\n",
    "    sample_size: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format a snippet of the table data for the LLM prompt.\n",
    "    Shows the first `sample_size` rows and the last `sample_size` rows.\n",
    "    \"\"\"\n",
    "    table_data_snippet = \"[\"\n",
    "    rows = table_data.tolist()\n",
    "    total_rows = len(rows)\n",
    "    \n",
    "    # If table is small enough, just show the whole thing\n",
    "    if total_rows <= (sample_size * 3):\n",
    "        for i, row in enumerate(rows):\n",
    "            table_data_snippet += str(row)\n",
    "            if i < total_rows - 1:\n",
    "                table_data_snippet += \",\\n \"\n",
    "        table_data_snippet += \"]\"\n",
    "        return table_data_snippet\n",
    "\n",
    "    # Format top rows\n",
    "    top_rows = rows[:sample_size]\n",
    "    table_data_snippet += str(top_rows[0])\n",
    "    for row in top_rows[1:]:\n",
    "        table_data_snippet += (\",\\n \"+str(row))\n",
    "\n",
    "    # Format middle rows\n",
    "    middle_rows = random.sample(\n",
    "        rows[sample_size:-sample_size], \n",
    "        sample_size\n",
    "    )\n",
    "    for row in middle_rows:\n",
    "        table_data_snippet += (\",\\n \"+str(row))\n",
    "            \n",
    "    # Format bottom rows\n",
    "    bottom_rows = rows[-sample_size:]\n",
    "    table_data_snippet += \",\\n ...\\n \" + str(bottom_rows[0])\n",
    "    for row in bottom_rows[1:]:\n",
    "        table_data_snippet += (\",\\n \"+str(row))\n",
    "    table_data_snippet += \"]\"\n",
    "    return table_data_snippet\n",
    "\n",
    "def _format_rows(rows: List[List[Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Format the rows for the LLM prompt.\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return \"[]\"\n",
    "    if len(rows) == 1:\n",
    "        return str(rows[0])\n",
    "    rows_snippet = \"[\" + str(rows[0])\n",
    "    for row in rows[1:]:\n",
    "        rows_snippet += \",\\n \" + str(row)\n",
    "    rows_snippet += \"]\"\n",
    "    return rows_snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dca6a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Danh mục', 'Tên món', 'Giá', 'Ghi chú'],\n",
      " ['Sashimi', 'HOKKAIDO DELUXE', '566.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Sashimi', 'TORO SALMON SASHIMI', '155.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Sashimi', 'SHAKO SASHIMI', '172.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Sashimi', 'SANSHUMORI PREMIUM', '345.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.']]\n"
     ]
    }
   ],
   "source": [
    "print(_format_rows(tables[0].data.tolist()[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "642833fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Danh mục', 'Tên món', 'Giá', 'Ghi chú'],\n",
      " ['Sashimi', 'HOKKAIDO DELUXE', '566.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Sashimi', 'TORO SALMON SASHIMI', '155.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Sushi', 'SHIME SABA NIGIRI', '73.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Special Set', 'SANMA TERIYAKI OR SHIOYAKI', '87.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Dessert', 'ICE CREAM PARFAIT - MATCHA', '99.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ...\n",
      " ['Drink', 'Matcha Iced Blend', '79.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Drink', 'Dalat Cider House Apple', '67.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.'],\n",
      " ['Drink', 'Fujiwa Hydrogen Water', '36.000', 'Tất cả giá trên chưa bao gồm 10% thuế VAT.']]\n"
     ]
    }
   ],
   "source": [
    "print(_format_table_data_snippet(tables[0].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e65c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_structure\": {\n",
      "    \"header_indices\": [0],\n",
      "    \"footer_indices\": null\n",
      "  },\n",
      "  \"pydantic_schema\": {\n",
      "    \"title\": \"RowData\",\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"Danh_muc\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Category of the menu item (e.g., Sashimi, Special Set, Drink)\"\n",
      "      },\n",
      "      \"Ten_mon\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Name of the menu item\"\n",
      "      },\n",
      "      \"Gia\": {\n",
      "        \"type\": \"number\",\n",
      "        \"description\": \"Price of the item in Vietnamese Dong (VND), formatted as float\"\n",
      "      },\n",
      "      \"Ghi_chu\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"General note about pricing (all prices exclude 10% VAT)\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\"Danh_muc\", \"Ten_mon\", \"Gia\", \"Ghi_chu\"]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get \n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
    ")\n",
    "\n",
    "resp_content = client.chat.completions.create(\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": EXTRACT_STRUCTURE_TEMPLATE.replace(\n",
    "        \"{{table_data_snippet}}\",\n",
    "        _format_table_data_snippet(tables[0].data)\n",
    "    )}],\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    presence_penalty=1,\n",
    "    extra_body = {\n",
    "        \"chat_template_kwargs\": {'enable_thinking': True},\n",
    "        \"top_k\": 20,\n",
    "        \"mip_p\": 0,\n",
    "    },\n",
    ").choices[0].message.content\n",
    "\n",
    "\n",
    "JSON_PATTERN = re.compile(r\"```json\\n(.*?)\\n```\", re.DOTALL)\n",
    "print(JSON_PATTERN.findall(resp_content)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f38b9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = json.loads(JSON_PATTERN.findall(resp_content)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd99b23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header_indices': [0], 'footer_indices': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"table_structure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f0b05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'title': 'RowData', 'type': 'object', 'properties': {'Danh_muc': {'type': 'string', 'description': 'Category of the menu item (e.g., Sashimi, Special Set, Drink)'}, 'Ten_mon': {'type': 'string', 'description': 'Name of the menu item'}, 'Gia': {'type': 'number', 'description': 'Price of the item in Vietnamese Dong (VND), formatted as float'}, 'Ghi_chu': {'type': 'string', 'description': 'General note about pricing (all prices exclude 10% VAT)'}}, 'required': ['Danh_muc', 'Ten_mon', 'Gia', 'Ghi_chu']}\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tmp[\"pydantic_schema\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "066b8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = tables[0].data.tolist()\n",
    "\n",
    "transform_prompt = TRANSFORM_DATA_TEMPLATE.replace(\n",
    "    \"{{raw_header}}\",\n",
    "    _format_rows([\n",
    "        data_list[i] for i in tmp[\"table_structure\"][\"header_indices\"]\n",
    "    ])\n",
    ").replace(\n",
    "    \"{{raw_row}}\",\n",
    "    _format_rows(data_list[3:4])\n",
    ").replace(\n",
    "    \"{{pydantic_schema}}\",\n",
    "    str(tmp[\"pydantic_schema\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "444a86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": transform_prompt}],\n",
    "    # stream=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    presence_penalty=1,\n",
    "    extra_body = {\n",
    "        \"chat_template_kwargs\": {'enable_thinking': False},\n",
    "        \"top_k\": 20,\n",
    "        \"mip_p\": 0,\n",
    "        \"guided_json\": tmp[\"pydantic_schema\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "# for chunk in response:\n",
    "#     print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4748abfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(content)[\"Gia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# from typing import List, Dict, Any\n",
    "# from openai import AsyncOpenAI\n",
    "\n",
    "# # Initialize the async client\n",
    "# # The client automatically picks up the OPENAI_API_KEY environment variable\n",
    "# async_client = AsyncOpenAI(\n",
    "#     base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "#     api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "# )\n",
    "\n",
    "\n",
    "# def format_user_prompt(input_data: Any) -> str:\n",
    "#     \"\"\"\n",
    "#     Format the user input into a prompt.\n",
    "#     You should implement this function based on your needs.\n",
    "    \n",
    "#     Args:\n",
    "#         input_data: The input data to format\n",
    "        \n",
    "#     Returns:\n",
    "#         str: The formatted prompt\n",
    "#     \"\"\"\n",
    "#     # TODO: Implement your format_user_prompt logic here\n",
    "#     # For now, returning a placeholder\n",
    "#     return str(input_data)\n",
    "\n",
    "\n",
    "# async def process_single_input(\n",
    "#     input_data: Any,\n",
    "# ) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Process a single input asynchronously.\n",
    "    \n",
    "#     Args:\n",
    "#         input_data: The input data to process\n",
    "        \n",
    "#     Returns:\n",
    "#         Dict containing:\n",
    "#             - success: bool indicating if the request succeeded\n",
    "#             - input_data: The original input data\n",
    "#             - response: The API response content (if successful)\n",
    "#             - error: Error message (if failed)\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Format the user prompt\n",
    "#         prompt = format_user_prompt(input_data)\n",
    "        \n",
    "#         # Make the async API call\n",
    "#         chat_completion = await async_client.chat.completions.create(\n",
    "#             model=os.getenv(\"LLM_MODEL\"),\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             \"success\": True,\n",
    "#             \"input_data\": input_data,\n",
    "#             \"response\": chat_completion.choices[0].message.content,\n",
    "#             \"error\": None\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         return {\n",
    "#             \"success\": False,\n",
    "#             \"input_data\": input_data,\n",
    "#             \"response\": None,\n",
    "#             \"error\": str(e)\n",
    "#         }\n",
    "\n",
    "\n",
    "# async def process_queue_batch(\n",
    "#     queue: List[Any],\n",
    "# ) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"\n",
    "#     Process all items in the queue asynchronously.\n",
    "    \n",
    "#     Args:\n",
    "#         queue: List of input items to process\n",
    "        \n",
    "#     Returns:\n",
    "#         List of result dictionaries from process_single_input\n",
    "#     \"\"\"\n",
    "#     # Create tasks for all items in the queue\n",
    "#     tasks = [process_single_input(item) for item in queue]\n",
    "    \n",
    "#     # Run all tasks concurrently and wait for completion\n",
    "#     results = await asyncio.gather(*tasks)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "\n",
    "# def get_error_samples(results: List[Dict[str, Any]]) -> List[Any]:\n",
    "#     \"\"\"\n",
    "#     Extract input data from failed samples.\n",
    "    \n",
    "#     Args:\n",
    "#         results: List of result dictionaries\n",
    "        \n",
    "#     Returns:\n",
    "#         List of input data that failed\n",
    "#     \"\"\"\n",
    "#     return [\n",
    "#         result[\"input_data\"]\n",
    "#         for result in results\n",
    "#         if not result[\"success\"]\n",
    "#     ]\n",
    "\n",
    "\n",
    "# async def main(\n",
    "#     initial_queue: List[Any],\n",
    "#     max_retries: int = 3,\n",
    "# ) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"\n",
    "#     Main function that processes a queue with retry logic.\n",
    "    \n",
    "#     Args:\n",
    "#         initial_queue: Initial list of items to process\n",
    "#         max_retries: Maximum number of retry attempts\n",
    "        \n",
    "#     Returns:\n",
    "#         List of all result dictionaries\n",
    "#     \"\"\"\n",
    "#     all_results = []\n",
    "#     queue = initial_queue.copy()\n",
    "    \n",
    "#     for attempt in range(max_retries):\n",
    "#         if not queue:\n",
    "#             print(f\"No more items to process after attempt {attempt + 1}\")\n",
    "#             break\n",
    "        \n",
    "#         print(f\"Attempt {attempt + 1}/{max_retries}: Processing {len(queue)} items...\")\n",
    "        \n",
    "#         # Process all items in the queue asynchronously\n",
    "#         results = await process_queue_batch(queue)\n",
    "#         all_results.extend(results)\n",
    "        \n",
    "#         # Check for error samples\n",
    "#         error_samples = get_error_samples(results)\n",
    "        \n",
    "#         if not error_samples:\n",
    "#             print(f\"All items processed successfully after attempt {attempt + 1}\")\n",
    "#             break\n",
    "        \n",
    "#         print(f\"Found {len(error_samples)} error samples. Retrying...\")\n",
    "        \n",
    "#         # Push error samples back to queue for retry\n",
    "#         queue = error_samples\n",
    "    \n",
    "#     # Print summary\n",
    "#     successful = sum(1 for r in all_results if r[\"success\"])\n",
    "#     failed = len(all_results) - successful\n",
    "#     print(f\"\\nSummary: {successful} successful, {failed} failed out of {len(all_results)} total\")\n",
    "    \n",
    "#     return all_results\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example initial queue\n",
    "#     initial_queue = [\n",
    "#         \"Explain asynchronous programming in Python\",\n",
    "#         \"What is machine learning?\",\n",
    "#         \"Tell me about Python decorators\",\n",
    "#     ]\n",
    "    \n",
    "#     # Run the main function\n",
    "#     results = asyncio.run(main(initial_queue, max_retries=3))\n",
    "    \n",
    "#     # Print results\n",
    "#     for i, result in enumerate(results):\n",
    "#         if result[\"success\"]:\n",
    "#             print(f\"\\nResult {i+1} (Success):\")\n",
    "#             print(result[\"response\"])\n",
    "#         else:\n",
    "#             print(f\"\\nResult {i+1} (Failed):\")\n",
    "#             print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6f635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f81d17",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37598a24",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf5f5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72407583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
