{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90685755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from typing import Optional, List, Dict\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ceb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(filepath: str) -> List[dict]:\n",
    "    with open(filepath) as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def write_jsonl(data: List[dict], filepath: str):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for line in data:\n",
    "            f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035266c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = read_jsonl(\"/Users/vinhnguyen/Projects/ext-chatbot/resources/logs/exports_1766646264633-lf-traces-export-cmio1vjfs000ynv0795mpsunw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405c2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "group_by_sessionId = {}\n",
    "for s in logs_data:\n",
    "    sessionId = s[\"sessionId\"]\n",
    "    if sessionId not in group_by_sessionId:\n",
    "        group_by_sessionId[sessionId] = []\n",
    "    if \"guru\" in s[\"tags\"]:\n",
    "        group_by_sessionId[sessionId].append(s)\n",
    "\n",
    "for sessionId in group_by_sessionId:\n",
    "    sorted_list = sorted(group_by_sessionId[sessionId], key=lambda x: datetime.fromisoformat(x['timestamp'].replace('Z', '+00:00')))\n",
    "    group_by_sessionId[sessionId] = sorted_list\n",
    "\n",
    "print(len(group_by_sessionId))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f936818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "conversations = []\n",
    "for sessionId in list(group_by_sessionId.keys()):\n",
    "    conversation = []\n",
    "    if len(group_by_sessionId[sessionId]) == 0:\n",
    "        continue\n",
    "    current_ind = len(group_by_sessionId[sessionId])-1\n",
    "    count = 0\n",
    "    while True:\n",
    "        current_history = json.loads(group_by_sessionId[sessionId][current_ind][\"metadata\"][\"history\"])\n",
    "        conversation = current_history + conversation\n",
    "        current_ind -= len(current_history)//2\n",
    "        if current_ind <= 0:\n",
    "            break\n",
    "        count += 1\n",
    "        if count > 1000:\n",
    "            print(current_ind)\n",
    "            break\n",
    "    \n",
    "    try:\n",
    "        conversation.extend([\n",
    "            {\"role\": \"user\", \"content\": group_by_sessionId[sessionId][-1][\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": json.loads(group_by_sessionId[sessionId][-1][\"output\"])[\"user_msg\"]}\n",
    "        ])\n",
    "    except Exception:\n",
    "        conversation.extend([\n",
    "            {\"role\": \"user\", \"content\": group_by_sessionId[sessionId][-1][\"input\"]},\n",
    "        ])\n",
    "    refined_conversation = []\n",
    "    for ind in range(len(conversation)):\n",
    "        if ind == 0:\n",
    "            refined_conversation.append(conversation[ind])\n",
    "            continue\n",
    "        if conversation[ind][\"role\"] == conversation[ind-1][\"role\"]:\n",
    "            if conversation[ind][\"content\"] == conversation[ind-1][\"content\"]:\n",
    "                continue\n",
    "            else:\n",
    "                new_content = conversation[ind-1][\"content\"] + conversation[ind][\"content\"]\n",
    "                refined_conversation.pop()\n",
    "                refined_conversation.append({\n",
    "                    \"role\": conversation[ind][\"role\"], \n",
    "                    \"content\": new_content\n",
    "                })\n",
    "        else:\n",
    "            refined_conversation.append(conversation[ind])\n",
    "    conversations.append(refined_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e561bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "for conversation in conversations:\n",
    "    for ind in range(len(conversation)):\n",
    "        if conversation[ind][\"role\"] == \"user\":\n",
    "            test_dataset.append({\n",
    "                \"conversation_history\": conversation[:ind],\n",
    "                \"current_message\": conversation[ind][\"content\"]\n",
    "            })\n",
    "\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65378c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_route_api(\n",
    "    current_message: str,\n",
    "    conversation_history: Optional[List[Dict[str, str]]] = None,\n",
    "    base_url: str = \"http://localhost:8000\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Asynchronously call the route API endpoint.\n",
    "    \n",
    "    Args:\n",
    "        current_message: Current user message to process\n",
    "        conversation_history: Optional conversation history in format \n",
    "                            [{'role': 'user'|'assistant', 'content': '...'}]\n",
    "        base_url: Base URL of the API server (default: http://localhost:8000)\n",
    "    \n",
    "    Returns:\n",
    "        The data_source string returned by the API (e.g., 'sql', 'vector', or 'none')\n",
    "    \n",
    "    Raises:\n",
    "        httpx.HTTPError: If the API request fails\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/route\"\n",
    "    payload = {\n",
    "        \"current_message\": current_message,\n",
    "        \"conversation_history\": conversation_history\n",
    "    }\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=3000.0) as client:\n",
    "        response = await client.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result[\"data_source\"]\n",
    "\n",
    "\n",
    "async def call_route_api_batch(\n",
    "    requests: List[Dict[str, any]],\n",
    "    base_url: str = \"http://localhost:8000\",\n",
    "    max_concurrent: int = 10\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Asynchronously call the route API endpoint for multiple requests in batch.\n",
    "    \n",
    "    Args:\n",
    "        requests: List of dicts with 'current_message' and optional 'conversation_history'\n",
    "        base_url: Base URL of the API server (default: http://localhost:8000)\n",
    "        max_concurrent: Maximum number of concurrent requests (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        List of data_source strings in the same order as input requests\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def call_with_semaphore(request_data):\n",
    "        async with semaphore:\n",
    "            return await call_route_api(\n",
    "                current_message=request_data[\"current_message\"],\n",
    "                conversation_history=request_data.get(\"conversation_history\"),\n",
    "                base_url=base_url\n",
    "            )\n",
    "    \n",
    "    tasks = [call_with_semaphore(req) for req in requests]\n",
    "    return await tqdm_asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e45db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [03:21<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "route_results = await call_route_api_batch(\n",
    "    test_dataset,\n",
    "    base_url=\"http://10.164.84.47:8321\",\n",
    "    max_concurrent=10\n",
    ")\n",
    "\n",
    "filter_test_dataset = []\n",
    "for route_result, sample in zip(route_results, test_dataset):\n",
    "    if route_result == \"sql\":\n",
    "        filter_test_dataset.append(sample)\n",
    "print(len(filter_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c3e5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(\n",
    "    random.sample(filter_test_dataset, min(200, len(filter_test_dataset))), \n",
    "    \"/Users/vinhnguyen/Projects/ext-chatbot/resources/logs/batdongsan_test.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42356f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5eff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
